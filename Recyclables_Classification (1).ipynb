{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uaGrH4H_KRn"
      },
      "source": [
        "# My First Machine Learning Project: Recyclables Classification\n",
        "\n",
        "I thought long and hard about my first personal project because I want it to be meaningful and purposeful and also aid in my machine learning learning journey and into computer vision. Everywhere I search there is already a project or a blog written about solving a certain problem, such as identifying and classfying local cuisines, or generating music. After researching hard and long, I have decided to just start and work on recyclables classification despite there having some work done on it as well. It is simple enough for a beginner like myself and it is quite meaningful for the environment.\n",
        "\n",
        "We will be looking at the dataset provided by [garythung](https://github.com/garythung/trashnet). Since this is my first personal solo project, I do not want to be too ambitious and just want to learn the ropes and process of creating a model. Based on this [news article](https://www.channelnewsasia.com/singapore/what-can-be-recycled-plastic-paper-glass-metal-recycling-bin-box-tips-nea-3100521),  main recyclables in Singapore are glass, metal, paper and plastic, hence we shall aim to classify these 4 recyclables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWd02YYN_ROY"
      },
      "source": [
        "# First Look at Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDJOpwWazphJ"
      },
      "source": [
        "## Check System Specifications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xS3F6aSQzmnW"
      },
      "outputs": [],
      "source": [
        "# Check System Specs\n",
        "import sys\n",
        "import multiprocessing\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  print('Python Version')\n",
        "  print(sys.version)\n",
        "  print('Version info.')\n",
        "  print(sys.version_info)\n",
        "  print('Number of CPU: ', multiprocessing.cpu_count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm-PlK8KA8Ar"
      },
      "source": [
        "## *Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLKhTFk5MaqA",
        "outputId": "ac91b24a-e58f-4d5c-a5e2-1f3958f7bea9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.10/dist-packages (1.3.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "## Import\n",
        "import os\n",
        "import sys\n",
        "import multiprocessing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#Preprocessing\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Models\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "!pip install catboost\n",
        "import catboost\n",
        "from catboost import CatBoost\n",
        "!pip install keras-tuner\n",
        "\n",
        "#Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Storage\n",
        "import pyarrow.feather as feather\n",
        "\n",
        "#Tuning\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmdMyX18e22V"
      },
      "source": [
        "## *Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOUw_7jFiWU6",
        "outputId": "88e86ff7-4587-46a8-e5ff-1eccdd5c6010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "## Mount Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7om_kRQWHHu"
      },
      "outputs": [],
      "source": [
        "# Bing Image Downloader\n",
        "# !pip install bing-image-downloader\n",
        "# from bing_image_downloader import downloader\n",
        "# dir = '/content/drive/MyDrive/Colab Notebooks/Recyclables Images'\n",
        "# downloader.download('paper garbage',limit=5,output_dir = dir,adult_filter_off = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVJKCs67jQ9p",
        "outputId": "8166d73e-3608-405b-fca2-9081c1a4ae67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "plastic_image_directory = ('/content/gdrive/MyDrive/Garbage Classification/plastic')\n",
        "# metal_image_directory = ('C:\\\\Users\\\\Rui Han\\\\Desktop\\\\Coding\\\\Recyclables Classification\\\\Garbage Classification\\\\metal')\n",
        "image_filename = 'plastic20.jpg'\n",
        "img = Image.open(os.path.join(metal_image_directory,image_filename))\n",
        "pixel_array = np.asarray(img)\n",
        "# print(pixel_array)\n",
        "print(pixel_array.shape)\n",
        "\n",
        "#Images have (x,y) pixels up to 255 for RGB\n",
        "#However, different images have different resolutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g_IYkmD_Fxi"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOs3k-xGteBW"
      },
      "outputs": [],
      "source": [
        "print(pixel_array.shape)\n",
        "hipixel = pixel_array.reshape(len(pixel_array),-1)\n",
        "print(hipixel.shape)\n",
        "hidf = pd.DataFrame(hipixel)\n",
        "display(hidf.tail())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaURPrHrBOQN"
      },
      "source": [
        "# Data Wrangling Part I: Data Playing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b-UsJycBSPa"
      },
      "source": [
        "## Choosing Resolution of Images\n",
        "\n",
        "Each image has different resolution so it is imperative that we standardise the resolution so as to have the same number of features for all. This [site](https://sh-tsang.medium.com/review-learning-to-resize-images-for-computer-vision-tasks-image-classification-image-quality-c05cbe284bc6) suggests a 224x224 so we shall try that first. For the sake of simplicity of our model, we shall do 224x224 for all images, regardless of smaller or bigger."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tImYA0YaIGC"
      },
      "outputs": [],
      "source": [
        "image = Image.open(os.path.join(metal_image_directory,image_filename))\n",
        "resized_image = image.resize((224,224))\n",
        "resized_image.save('/content/drive/MyDrive/Garbage Classification/metal/test.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V17v5bkdfAQm"
      },
      "source": [
        "## Extracting Pixel Values as Arrays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zT2OpYnyfHJM"
      },
      "outputs": [],
      "source": [
        "resized_image_array = np.asarray(resized_image)\n",
        "print(resized_image_array)\n",
        "print(resized_image_array.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZpYVE8Re4XM"
      },
      "source": [
        "## Visualising Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7gBIBlUe6t3"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.imshow(resized_image_array)\n",
        "plt.title('metal_521')\n",
        "plt.axis('off')\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcZnyMyTh44b"
      },
      "source": [
        "# Data Wrangling Part II: Renaming and Resizing Data\n",
        "There are 3,737 glass images of which 607 are specially named brown glass, 607 are specially named green glass, and 775 are specially named white glass. The rest of 1,726 are named glass but have a mix of all 3 colours.\n",
        "\n",
        "There are 1,986 metal images, 2,092 paper images and 2,302 plastic images.\n",
        "\n",
        "I have decided to remove the specially named glass images to keep the number of images for each category similar.\n",
        "\n",
        "We will first rename all the images for ease of handling.\n",
        "\n",
        "Then we will resize every image to a size of 224x224.\n",
        "\n",
        "Did a scan through the images and found that there are some mislabelled images so did the following changes:\n",
        "```\n",
        "glass: 1726 > 1725 (glass97)\n",
        "metal: 1986>1979 (+ 1 from glass97) (metal841 macs box, metal1274 white circle with right arrow, metal1394 chocolate cake, metal1766 macs box, metal1892 cup noodle, metal1900 green instant, metal1934 golden cap, metal1985 cup noodle)\n",
        "paper: 2092>2088 (paper593 plastic, paper594 plastic, paper597 plastic, paper598 plastic)\n",
        "plastic: 2303>2306 (+4 from papers)\n",
        "New Total = 8098\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcDic6hFOWLk",
        "outputId": "9370c9fa-63ed-47fe-a6e1-e908e575eb0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Recyclables Images/metal\n",
            "metal151.jpg\n"
          ]
        }
      ],
      "source": [
        "old_dir = '/content/drive/MyDrive/Garbage Classification/raw_metal'\n",
        "new_dir = old_dir.replace('raw_','')\n",
        "print(new_dir)\n",
        "\n",
        "new_filename = old_dir.split('_')[-1] + str(a) + '.jpg'\n",
        "print(new_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP9wSM43PYMc"
      },
      "source": [
        "## *Directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvtzJbKN1sJ3"
      },
      "outputs": [],
      "source": [
        "## Directories\n",
        "raw_metal_image_directory = ('/content/gdrive/MyDrive/Garbage Classification/raw_metal')\n",
        "raw_glass_image_directory = ('/content/gdrive/MyDrive/Garbage Classification/raw_glass')\n",
        "raw_paper_image_directory = ('/content/gdrive/MyDrive/Garbage Classification/raw_paper')\n",
        "raw_plastic_image_directory = ('/content/gdrive/MyDrive/Garbage Classification/raw_plastic')\n",
        "raw_image_directories = [raw_metal_image_directory,raw_glass_image_directory,raw_paper_image_directory,raw_plastic_image_directory]\n",
        "\n",
        "metal_image_directory = ('/content/gdrive/MyDrive/Garbage Classification/metal')\n",
        "glass_image_directory = ('/content/gdrive/MyDrive/Garbage Classification/glass')\n",
        "paper_image_directory = ('/content/gdrive/MyDrive/Garbage Classification/paper')\n",
        "plastic_image_directory = ('/content/gdrive/MyDrive/Garbage Classification/plastic')\n",
        "created_image_directories = [\n",
        "    #metal_image_directory,glass_image_directory,paper_image_directory,\n",
        "    plastic_image_directory]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIdRlYhSaRP_"
      },
      "source": [
        "## Renaming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRS3e1DPiEPZ",
        "outputId": "263beaee-4532-4856-962c-aa80dad3852c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Renamed successfully!\n"
          ]
        }
      ],
      "source": [
        "## Renaming\n",
        "\n",
        "# Delete all created images and empty folders\n",
        "for directory in created_image_directories:\n",
        "  dir = directory\n",
        "  if os.path.exists(os.path.join(dir)):\n",
        "    for filename in os.listdir(dir):\n",
        "      os.remove(os.path.join(dir, filename))\n",
        "  else:\n",
        "    os.makedirs(dir)\n",
        "\n",
        "for old_directory in raw_image_directories:\n",
        "  old_dir = old_directory\n",
        "  new_dir = old_dir.replace('raw_','')\n",
        "  a = 1\n",
        "  for filename in os.listdir(old_dir):\n",
        "      image = Image.open(os.path.join(old_dir,filename))\n",
        "      if image.mode != 'RGB':\n",
        "        image = image.convert('RGB')\n",
        "      new_filename = old_dir.split('_')[-1] + str(a) + '.jpg'\n",
        "      a += 1\n",
        "      image.save(os.path.join(new_dir,new_filename))\n",
        "\n",
        "print('Renamed successfully!')\n",
        "\n",
        "## Old code that works\n",
        "# for dir in created_image_directories:\n",
        "#   directory = dir\n",
        "#   a = 1\n",
        "#   for filename in os.listdir(directory):\n",
        "#     if filename.startswith(directory.split('/')[-1]):\n",
        "#       image = Image.open(os.path.join(directory,filename))\n",
        "#       if image.mode == 'RGBA':\n",
        "#         image = image.convert('RGB')\n",
        "#       new_filename = directory.split('/')[-1] + str(a) + '.jpg'\n",
        "#       a += 1\n",
        "#       image.save(os.path.join(directory,new_filename))\n",
        "#       if os.path.exists(os.path.join(directory,filename)):\n",
        "#         os.remove(os.path.join(directory,filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCnhX_o7aM7t",
        "outputId": "cb046fe2-7604-4fa4-ccb7-92190b8bfcd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Renamed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Renaming with 8 CPU Cores\n",
        "\n",
        "# Delete all created images and empty folders\n",
        "for directory in created_image_directories:\n",
        "  dir = directory\n",
        "  if os.path.exists(os.path.join(dir)):\n",
        "    for filename in os.listdir(dir):\n",
        "      os.remove(os.path.join(dir, filename))\n",
        "  else:\n",
        "    os.makedirs(dir)\n",
        "\n",
        "def rename_image(image_path,aa):\n",
        "  # global aa\n",
        "  new_dir = image_path.rsplit('/', 1)[0].replace('raw_', '')\n",
        "  image = Image.open(image_path)\n",
        "  if image.mode != 'RGB':\n",
        "    image = image.convert('RGB')\n",
        "  new_filename = image_path.split('/')[-2].replace('raw_', '')\n",
        "  aa += 1\n",
        "  image.save(os.path.join(new_dir,new_filename))\n",
        "\n",
        "\n",
        "  if __name__ == '__main__':\n",
        "    raw_image_directories = [raw_metal_image_directory,raw_glass_image_directory,raw_paper_image_directory,raw_plastic_image_directory]\n",
        "\n",
        "    pool = multiprocessing.Pool(processes=8)\n",
        "\n",
        "    aa = 0\n",
        "\n",
        "    for directory in raw_image_directories:\n",
        "      dir = directory\n",
        "      image_paths = [os.path.join(dir,filename) for filename in os.listdir(dir)]\n",
        "      # pool.map(rename_image,image_paths)\n",
        "      args = [(image_path, aa) for aa, image_path in enumerate(image_paths, start=1)]\n",
        "      pool.starmap(rename_image, args)\n",
        "\n",
        "    pool.close()\n",
        "    pool.join()\n",
        "\n",
        "print('Renamed successfully!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBdyq8wESMf1",
        "outputId": "b42ea4fc-4fe4-4540-e1bb-6c250b53e0e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "metal count is equal to 1986\n",
            "glass count is equal to 1726\n",
            "paper count is equal to 2092\n",
            "plastic count is equal to 2302\n",
            "metal count is equal to 0\n",
            "glass count is equal to 0\n",
            "paper count is equal to 0\n",
            "plastic count is equal to 0\n"
          ]
        }
      ],
      "source": [
        "# Check if renaming was done right\n",
        "\n",
        "for directory in (raw_image_directories):\n",
        "  dir = directory\n",
        "  raw_image_count = 0\n",
        "  for filename in os.listdir(dir):\n",
        "    if os.path.isfile(os.path.join(dir,filename)):\n",
        "      raw_image_count += 1\n",
        "  print(dir.split('_')[-1] + ' count is equal to ' + str(raw_image_count))\n",
        "\n",
        "for directory in (created_image_directories):\n",
        "  dir = directory\n",
        "  created_image_count = 0\n",
        "  for filename in os.listdir(dir):\n",
        "    if os.path.isfile(os.path.join(dir,filename)):\n",
        "      created_image_count += 1\n",
        "  print(dir.split('/')[-1] + ' count is equal to ' + str(created_image_count))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-IfdeMUaZXG"
      },
      "source": [
        "## Resizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZI8sUvFlqea",
        "outputId": "9dae4529-c458-4645-82e0-7df72f1efe9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resize successful!\n"
          ]
        }
      ],
      "source": [
        "## Resizing\n",
        "created_image_directories = [metal_image_directory,glass_image_directory,paper_image_directory,plastic_image_directory]\n",
        "\n",
        "rd = 64 #resize_dimension\n",
        "for directory in created_image_directories:\n",
        "  dir = directory\n",
        "  for filename in os.listdir(dir):\n",
        "    image = Image.open(os.path.join(dir,filename))\n",
        "    new_filename = 'resized_' + filename\n",
        "    resized_image = image.resize((rd,rd))\n",
        "    resized_image.save(os.path.join(dir,new_filename))\n",
        "    os.remove(os.path.join(dir,filename))\n",
        "    os.rename(os.path.join(dir,new_filename), os.path.join(dir,filename))\n",
        "print('Resize successful!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNByQkPaIUaf",
        "outputId": "02247c84-0cd9-496f-c04f-c3c7c48835a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resize successfully! \n"
          ]
        }
      ],
      "source": [
        "## Resizing with 8 CPU cores\n",
        "import multiprocessing\n",
        "\n",
        "rd = 64 #resize_dimension\n",
        "def resize_image(image_path):\n",
        "  image = Image.open(image_path)\n",
        "  new_filename = 'resized_' + os.path.basename(image_path)\n",
        "  resized_image = image.resize((rd,rd))\n",
        "  resized_image.save(os.path.join(dir,new_filename))\n",
        "  os.remove(image_path)\n",
        "  os.rename(os.path.join(dir,new_filename),image_path)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  created_image_directories = [metal_image_directory, glass_image_directory, paper_image_directory, plastic_image_directory]\n",
        "\n",
        "  pool = multiprocessing.Pool(processes=8)\n",
        "\n",
        "  for directory in created_image_directories:\n",
        "    dir = directory\n",
        "    image_paths = [os.path.join(dir,filename) for filename in os.listdir(dir)]\n",
        "    pool.map(resize_image,image_paths)\n",
        "\n",
        "  pool.close()\n",
        "  pool.join()\n",
        "\n",
        "print('Resize successfully! ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnTI3ZkEciQJ",
        "outputId": "a98defa9-ea17-413a-b677-dac3e92a1033"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "metal correct resized count is equal to 1986\n",
            "metal wrong resized count is equal to 0\n",
            "glass correct resized count is equal to 1726\n",
            "glass wrong resized count is equal to 0\n",
            "paper correct resized count is equal to 2092\n",
            "paper wrong resized count is equal to 0\n",
            "plastic correct resized count is equal to 2302\n",
            "plastic wrong resized count is equal to 0\n"
          ]
        }
      ],
      "source": [
        "# Check if resizing was done right\n",
        "created_image_directories = [metal_image_directory,glass_image_directory,paper_image_directory,plastic_image_directory]\n",
        "for directory in created_image_directories:\n",
        "  correct_width = rd\n",
        "  correct_height = rd\n",
        "  correct_resized_count = 0\n",
        "  wrong_resized_count = 0\n",
        "  dir = directory\n",
        "  for filename in os.listdir(dir):\n",
        "    image = Image.open(os.path.join(dir,filename))\n",
        "    width, height = image.size\n",
        "    if int(width) - correct_width == 0 and int(height) - correct_height == 0:\n",
        "      correct_resized_count += 1\n",
        "    else:\n",
        "      wrong_resized_count += 1\n",
        "  print(dir.split('/')[-1] + ' correct resized count is equal to ' + str(correct_resized_count))\n",
        "  print(dir.split('/')[-1] + ' wrong resized count is equal to ' + str(wrong_resized_count))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeCw9NOSYCYN"
      },
      "source": [
        "# Data Wrangling Part III: Forming .csv File and Restructuring Data\n",
        "\n",
        "We will first take each image and extract each pixel as a feature and be put into a Dataframe. There would be a total 8,106 samples each with 150,528(224x224x3), hence the shape would be 8106 x 150528. *change: 8,098 samples*\n",
        "\n",
        "*At this point I have hit a big wall because the code for forming the dataframe always took super long and at first I thought it was because of my inactivity at first so I tried doing it locally on Jupyter but that took an another day and it was still not done. I guessed it was a computational issue so I decided to rent cloud GPUs but I met many issues with that (such as syncing images to the instance, running the code on the instance) and it wasn't reliable. In the end, I opted for Google Colab pro which would save me all the hassle. I thought the code would be done fast but it has been 19h 30min thus far and so it made me realise that perhaps I would need to downsize the images quite a bit. From this [article](https://hasty.ai/docs/mp-wiki/training-parameters/batch-size#:~:text=%22For%20the%20most%20part%2C%20a,best%20to%20begin%20experimenting%20with.%22) and this [article](https://towardsdatascience.com/boost-your-image-classifier-e1cc7a56b59c), it suggests batch resizing and training the model on increasing dimensional size. For simplicity, I shall start with 32x32, then 64x64, 128x128, etc.*\n",
        "\n",
        "*I fixed the lengthy time it took and decided to work on the processing speed so I delved into multiprocessing and using the 8 CPU cores that Google Colab has. However, it has been a big failure of .feather files always generating samples from 1 directory or generating 20k samples in 1 .feather file. I decided to just cut out that multiprocessing step for simplicity, since data preprocessing is not the main point of this project.*\n",
        "\n",
        "We will then create a y variable for each sample.\n",
        "\n",
        "Then, randomly select 20% of each category to put into a test set. Then create their dataframe of target variable y and 224x224x3 pixel features X.\n",
        "\n",
        "This will be done for the other 80% of the training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itxyo5YriWz4"
      },
      "source": [
        "## Convert Pixels into .Feather file in Batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqCMRycFYSyO"
      },
      "outputs": [],
      "source": [
        "# Converting Pixels into .Feather 1.0\n",
        "test = '/content/gdrive/MyDrive/Garbage Classification/test'\n",
        "test_directories = [test]\n",
        "\n",
        "num_pixel_columns = rd**2 + 1\n",
        "num_all_columns = (rd**2 *3)\n",
        "rawdata = pd.DataFrame() #create empty dataframe\n",
        "column_names = ['label'] #create column names for each RGB 50176 pixels\n",
        "red, green, blue = 'R', 'G', 'B'\n",
        "colours = [red,green,blue]\n",
        "for colour in colours:\n",
        "  for i in range(1,num_pixel_columns):\n",
        "    column_names.append(colour + str(i))\n",
        "\n",
        "for directory in created_image_directories:\n",
        "  dir = directory\n",
        "  label =np.array(dir.split('/')[-1]).reshape(1,-1)\n",
        "  for filename in os.listdir(dir):\n",
        "    image = Image.open(os.path.join(dir,filename))\n",
        "    image_array = np.asarray(image).reshape(-1,num_all_columns)\n",
        "    image_array = np.concatenate((label,image_array),axis=1)\n",
        "    rawdata = pd.concat([rawdata,pd.DataFrame(image_array,columns=column_names)],ignore_index=True)\n",
        "    # rawdata = rawdata.append(pd.DataFrame(image_array,columns=column_names),ignore_index=True)\n",
        "# rawdata.to_csv('/content/drive/MyDrive/Colab Notebooks/Recyclables Images/rawdata.csv',index=False)\n",
        "feather.write_feather(rawdata,'/content/drive/MyDrive/Garbage Classification/rawdata.feather')\n",
        "\n",
        "print('File successfully saved!')\n",
        "display(rawdata.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Re6N6mFIs8v",
        "outputId": "66eb6b05-493f-44d5-e847-89bd5f88c6c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved 2000 to rawdata_batch_1.feather\n"
          ]
        }
      ],
      "source": [
        "# Converting Pixels to .Feather with 8 CPU Cores 2.0\n",
        "\n",
        "def pixel_to_feather(image_path, label, batch_size, batch_number):\n",
        "  global rawdata\n",
        "  image = Image.open(image_path)\n",
        "  image_array = np.asarray(image).reshape(-1,num_all_columns)\n",
        "  image_array = np.concatenate((label,image_array),axis=1)\n",
        "  rawdata = pd.concat([rawdata,pd.DataFrame(image_array,columns=column_names)],ignore_index=True)\n",
        "\n",
        "  # if len(rawdata) >= len(image_paths) or len(rawdata) >= batch_size:\n",
        "  #   feather_filename = f'rawdata_batch_{batch_number}.feather'\n",
        "  #   feather.write_feather(rawdata,f'/content/gdrive/MyDrive/Garbage Classification/{feather_filename}')\n",
        "  #   print(f'Saved {len(rawdata)} to {feather_filename}')\n",
        "  #   rawdata = pd.DataFrame(columns=column_names)\n",
        "\n",
        "  return rawdata\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  created_image_directories = [metal_image_directory,glass_image_directory,paper_image_directory,plastic_image_directory]\n",
        "\n",
        "  rd = 32 #resize_dimension\n",
        "  num_pixel_columns = rd**2 + 1\n",
        "  num_all_columns = (rd**2 *3)\n",
        "  column_names = ['label'] + [f'{colour}{i}' for colour in ['R','G','B'] for i in range(1,num_pixel_columns)]\n",
        "\n",
        "  rawdata = pd.DataFrame(columns=column_names)\n",
        "  batch_number = 1\n",
        "\n",
        "  image_paths = []\n",
        "\n",
        "  for directory in created_image_directories:\n",
        "      dir = directory\n",
        "      label = np.array(dir.split('/')[-1]).reshape(1,-1)\n",
        "      image_paths += [os.path.join(dir,filename) for filename in os.listdir(dir)]\n",
        "\n",
        "  batch_size = 2000\n",
        "  total_samples_in_directory = len(image_paths) #could be more or less than 2000\n",
        "  diff = total_samples_in_directory - batch_size\n",
        "  samples_start = 0\n",
        "  samples_processed = 0\n",
        "  samples_end = min(batch_size, total_samples_in_directory) #chooses whichever is lower: directory_samples or batch_size\n",
        "\n",
        "  with multiprocessing.Pool(processes=8) as pool:\n",
        "    while samples_processed < total_samples_in_directory:\n",
        "      current_image_paths = image_paths[samples_start:samples_end]\n",
        "      for image_path in current_image_paths:\n",
        "        rawdata = pixel_to_feather(image_path,label,batch_size,batch_number)\n",
        "        samples_processed += 1\n",
        "\n",
        "      if total_samples_in_directory > batch_size and samples_processed == batch_size:\n",
        "        feather_filename = f'rawdata_batch_{batch_number}.feather'\n",
        "        feather.write_feather(rawdata,f'/content/gdrive/MyDrive/Garbage Classification/{feather_filename}')\n",
        "        print(f'Saved {len(rawdata)} to {feather_filename}')\n",
        "        rawdata = pd.DataFrame(columns=column_names)\n",
        "        batch_number += 1\n",
        "\n",
        "        current_image_paths = image_paths[batch_size + 1:total_samples_in_directory]\n",
        "        for image_path in current_image_paths:\n",
        "          rawdata = pixel_to_feather(image_path,label,batch_size,batch_number)\n",
        "          samples_processed += 1\n",
        "\n",
        "          if samples_processed == total_samples_in_directory:\n",
        "            feather_filename = f'rawdata_batch_{batch_number}.feather'\n",
        "            feather.write_feather(rawdata,f'/content/gdrive/MyDrive/Garbage Classification/{feather_filename}')\n",
        "            print(f'Saved {len(rawdata)} to {feather_filename}')\n",
        "            rawdata = pd.DataFrame(columns=column_names)\n",
        "            batch_number += 1\n",
        "\n",
        "      if samples_processed == samples_end: #directory_samples <\\= batch_size\n",
        "        feather_filename = f'rawdata_batch_{batch_number}.feather'\n",
        "        feather.write_feather(rawdata,f'/content/gdrive/MyDrive/Garbage Classification/{feather_filename}')\n",
        "        print(f'Saved {len(rawdata)} to {feather_filename}')\n",
        "        rawdata = pd.DataFrame(columns=column_names)\n",
        "        batch_number += 1\n",
        "\n",
        "      # if batch_number == 2:\n",
        "      #   break\n",
        "\n",
        "print('Files saved successfully!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISRD9yqGUHe6"
      },
      "outputs": [],
      "source": [
        "# Converting Pixels to .Feather with 8 CPU Cores 2.1\n",
        "\n",
        "def pixel_to_feather(image_path, label):\n",
        "    global rawdata\n",
        "    image = Image.open(image_path)\n",
        "    image_array = np.asarray(image).reshape(-1, num_all_columns)\n",
        "    image_array = np.concatenate((label, image_array), axis=1)\n",
        "    rawdata = pd.concat([rawdata, pd.DataFrame(image_array, columns=column_names)], ignore_index=True)\n",
        "    return rawdata\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    created_image_directories = [metal_image_directory, glass_image_directory, paper_image_directory, plastic_image_directory]\n",
        "\n",
        "    rd = 32  # resize_dimension\n",
        "    num_pixel_columns = rd ** 2 + 1\n",
        "    num_all_columns = (rd ** 2 * 3)\n",
        "    column_names = ['label'] + [f'{colour}{i}' for colour in ['R', 'G', 'B'] for i in range(1, num_pixel_columns)]\n",
        "\n",
        "    rawdata = pd.DataFrame(columns=column_names)\n",
        "    batch_number = 1\n",
        "    samples_per_batch = 2000\n",
        "\n",
        "    with multiprocessing.Pool(processes=8) as pool:\n",
        "      for directory in created_image_directories:\n",
        "        dir = directory\n",
        "        label = np.array(dir.split('/')[-1]).reshape(1, -1)\n",
        "        image_paths = [os.path.join(dir, filename) for filename in os.listdir(dir)]\n",
        "        total_samples = len(image_paths)\n",
        "        batch_start = 0\n",
        "\n",
        "        while batch_start < total_samples:\n",
        "            batch_end = min(batch_start + samples_per_batch, total_samples)\n",
        "            current_image_paths = image_paths[batch_start:batch_end]\n",
        "\n",
        "            results = pool.starmap(pixel_to_feather, [(image_path,label) for image_path in current_image_paths])\n",
        "            rawdata = pd.concat(results, ignore_index=True)\n",
        "\n",
        "            feather_filename = f'rawdata_batch_{batch_number}.feather'\n",
        "            feather.write_feather(rawdata, f'/content/gdrive/MyDrive/Garbage Classification/{feather_filename}')\n",
        "            print(f'Saved {len(rawdata)} to {feather_filename}')\n",
        "\n",
        "            rawdata = pd.DataFrame(columns=column_names)  # Reset rawdata\n",
        "            batch_start = batch_end\n",
        "            batch_number += 1\n",
        "\n",
        "    print('Files saved successfully!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "PenpjPgEQYXH",
        "outputId": "fed617f1-3563-4073-a86b-77a114a8c8d2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-2519f5df319d>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcurrent_image_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpixel_to_feather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0mfeather_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'rawdata_batch_{batch_number}.feather'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-2519f5df319d>\u001b[0m in \u001b[0;36mpixel_to_feather\u001b[0;34m(image_path, label)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpixel_to_feather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mrawdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mimage_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_all_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mimage_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3227\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3228\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/MyDrive/Garbage Classification/plastic/plastic20.jpg'"
          ]
        }
      ],
      "source": [
        "## Converting Pixels into .Feather 1.1\n",
        "\n",
        "def pixel_to_feather(image_path, label):\n",
        "    global rawdata\n",
        "    image = Image.open(image_path)\n",
        "    image_array = np.asarray(image).reshape(-1, num_all_columns)\n",
        "    image_array = np.concatenate((label, image_array), axis=1)\n",
        "    rawdata = pd.concat([rawdata, pd.DataFrame(image_array, columns=column_names)], ignore_index=True)\n",
        "    return rawdata\n",
        "\n",
        "rd = 224  # resize_dimension\n",
        "num_pixel_columns = rd ** 2 + 1\n",
        "num_all_columns = (rd ** 2 * 3)\n",
        "column_names = ['label'] + [f'{colour}{i}' for colour in ['R', 'G', 'B'] for i in range(1, num_pixel_columns)]\n",
        "\n",
        "rawdata = pd.DataFrame(columns=column_names)\n",
        "batch_number = 5\n",
        "samples_per_batch = 1153\n",
        "\n",
        "for directory in created_image_directories:\n",
        "  dir = directory\n",
        "  label = np.array(dir.split('/')[-1]).reshape(1, -1)\n",
        "  image_paths = [os.path.join(dir, filename) for filename in os.listdir(dir)]\n",
        "  total_samples = len(image_paths)\n",
        "  batch_start = 0\n",
        "\n",
        "  while batch_start < total_samples:\n",
        "      batch_end = min(batch_start + samples_per_batch, total_samples)\n",
        "      current_image_paths = image_paths[batch_start:batch_end]\n",
        "\n",
        "      for image_path in current_image_paths:\n",
        "        data = pixel_to_feather(image_path,label)\n",
        "\n",
        "      feather_filename = f'rawdata_batch_{batch_number}.feather'\n",
        "      feather.write_feather(rawdata, f'/content/gdrive/MyDrive/Garbage Classification/{feather_filename}')\n",
        "      print(f'Saved {len(rawdata)} to {feather_filename}')\n",
        "\n",
        "      rawdata = pd.DataFrame(columns=column_names)  # Reset rawdata\n",
        "      batch_start = batch_end\n",
        "      batch_number += 1\n",
        "\n",
        "print('Files saved successfully!')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    with open('/content/gdrive/MyDrive/Garbage Classification/plastic/plastic20.jpg') as file:\n",
        "        pass\n",
        "    print(\"File found.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"File not found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qm7AmpdjGmNE",
        "outputId": "59519416-57f2-4126-da3c-55c54409d328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4MRx-VwN6d1"
      },
      "outputs": [],
      "source": [
        "# Viewing data\n",
        "\n",
        "df1 = feather.read_feather('/content/gdrive/MyDrive/Garbage Classification/rawdata_batch_1.feather')\n",
        "df2 = feather.read_feather('/content/gdrive/MyDrive/Garbage Classification/rawdata_batch_2.feather')\n",
        "df3 = feather.read_feather('/content/gdrive/MyDrive/Garbage Classification/rawdata_batch_3.feather')\n",
        "df4 = feather.read_feather('/content/gdrive/MyDrive/Garbage Classification/rawdata_batch_4.feather')\n",
        "df5 = feather.read_feather('/content/gdrive/MyDrive/Garbage Classification/rawdata_batch_5.feather')\n",
        "df6 = feather.read_feather('/content/gdrive/MyDrive/Garbage Classification/rawdata_batch_6.feather')\n",
        "\n",
        "for df in [df1,df2,df3,df4,df5,df6]:\n",
        "  print(df.shape)\n",
        "  display(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aloGrBitkMVu"
      },
      "source": [
        "## *Read file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "E9c4chHQhuMS",
        "outputId": "9814d5ee-d96a-4615-c84f-f48ee12be126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8106, 12289)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   label   R1   R2   R3   R4   R5   R6   R7   R8   R9  ... B4087 B4088 B4089  \\\n",
              "0  metal  255  255  255  255  255  255  255  255  255  ...   255   254   255   \n",
              "1  metal  253  253  253  253  253  253  253  253  253  ...   253   253   253   \n",
              "2  metal  220  221  239  220  221  239  219  220  238  ...   169   159   159   \n",
              "3  metal  159  112   60  163  115   66  170  118   71  ...    60   104    72   \n",
              "4  metal  126   93   62  129   96   65  134   99   69  ...   196   197   191   \n",
              "\n",
              "  B4090 B4091 B4092 B4093 B4094 B4095 B4096  \n",
              "0   255   252   255   255   252   255   255  \n",
              "1   253   253   253   253   253   253   253  \n",
              "2   171   162   162   172   165   165   175  \n",
              "3    51    91    60    42    82    53    35  \n",
              "4   193   195   186   187   192   183   184  \n",
              "\n",
              "[5 rows x 12289 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2089a39-3b85-4172-aadb-d6d3974672db\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>R1</th>\n",
              "      <th>R2</th>\n",
              "      <th>R3</th>\n",
              "      <th>R4</th>\n",
              "      <th>R5</th>\n",
              "      <th>R6</th>\n",
              "      <th>R7</th>\n",
              "      <th>R8</th>\n",
              "      <th>R9</th>\n",
              "      <th>...</th>\n",
              "      <th>B4087</th>\n",
              "      <th>B4088</th>\n",
              "      <th>B4089</th>\n",
              "      <th>B4090</th>\n",
              "      <th>B4091</th>\n",
              "      <th>B4092</th>\n",
              "      <th>B4093</th>\n",
              "      <th>B4094</th>\n",
              "      <th>B4095</th>\n",
              "      <th>B4096</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>metal</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>...</td>\n",
              "      <td>255</td>\n",
              "      <td>254</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>252</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>252</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>metal</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>...</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>metal</td>\n",
              "      <td>220</td>\n",
              "      <td>221</td>\n",
              "      <td>239</td>\n",
              "      <td>220</td>\n",
              "      <td>221</td>\n",
              "      <td>239</td>\n",
              "      <td>219</td>\n",
              "      <td>220</td>\n",
              "      <td>238</td>\n",
              "      <td>...</td>\n",
              "      <td>169</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>171</td>\n",
              "      <td>162</td>\n",
              "      <td>162</td>\n",
              "      <td>172</td>\n",
              "      <td>165</td>\n",
              "      <td>165</td>\n",
              "      <td>175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>metal</td>\n",
              "      <td>159</td>\n",
              "      <td>112</td>\n",
              "      <td>60</td>\n",
              "      <td>163</td>\n",
              "      <td>115</td>\n",
              "      <td>66</td>\n",
              "      <td>170</td>\n",
              "      <td>118</td>\n",
              "      <td>71</td>\n",
              "      <td>...</td>\n",
              "      <td>60</td>\n",
              "      <td>104</td>\n",
              "      <td>72</td>\n",
              "      <td>51</td>\n",
              "      <td>91</td>\n",
              "      <td>60</td>\n",
              "      <td>42</td>\n",
              "      <td>82</td>\n",
              "      <td>53</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>metal</td>\n",
              "      <td>126</td>\n",
              "      <td>93</td>\n",
              "      <td>62</td>\n",
              "      <td>129</td>\n",
              "      <td>96</td>\n",
              "      <td>65</td>\n",
              "      <td>134</td>\n",
              "      <td>99</td>\n",
              "      <td>69</td>\n",
              "      <td>...</td>\n",
              "      <td>196</td>\n",
              "      <td>197</td>\n",
              "      <td>191</td>\n",
              "      <td>193</td>\n",
              "      <td>195</td>\n",
              "      <td>186</td>\n",
              "      <td>187</td>\n",
              "      <td>192</td>\n",
              "      <td>183</td>\n",
              "      <td>184</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  12289 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2089a39-3b85-4172-aadb-d6d3974672db')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b2089a39-3b85-4172-aadb-d6d3974672db button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b2089a39-3b85-4172-aadb-d6d3974672db');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b1eab68b-88c2-4853-a621-c7298aa0056d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b1eab68b-88c2-4853-a621-c7298aa0056d')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b1eab68b-88c2-4853-a621-c7298aa0056d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "## Read and turn into one dataframe\n",
        "df1 = feather.read_feather('/content/gdrive/MyDrive/Garbage Classification/rawdata_batch_1.feather')\n",
        "df2 = feather.read_feather('/content/gdrive/MyDrive/Garbage Classification/rawdata_batch_2.feather')\n",
        "df3 = feather.read_feather('/content/gdrive/MyDrive/Garbage Classification/rawdata_batch_3.feather')\n",
        "df4 = feather.read_feather('/content/gdrive/MyDrive/Garbage Classification/rawdata_batch_4.feather')\n",
        "df5 = feather.read_feather('/content/gdrive/MyDrive/Garbage Classification/rawdata_batch_5.feather')\n",
        "df6 = feather.read_feather('/content/gdrive/MyDrive/Garbage Classification/rawdata_batch_6.feather')\n",
        "\n",
        "dfs = [df1,df2,df3,df4,df5,df6]\n",
        "data = pd.concat(dfs,axis=0)\n",
        "data.reset_index(drop=True,inplace=True)\n",
        "print(data.shape)\n",
        "display(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "Lpl7C-i2woJ7",
        "outputId": "70800246-8633-40e2-ab38-8751463574f2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      label   R1   R2   R3   R4   R5   R6   R7   R8   R9  ... B4087 B4088  \\\n",
              "0     metal  255  255  255  255  255  255  255  255  255  ...   255   254   \n",
              "1     metal  253  253  253  253  253  253  253  253  253  ...   253   253   \n",
              "2     metal  220  221  239  220  221  239  219  220  238  ...   169   159   \n",
              "3     metal  159  112   60  163  115   66  170  118   71  ...    60   104   \n",
              "4     metal  126   93   62  129   96   65  134   99   69  ...   196   197   \n",
              "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   \n",
              "1981  metal  255  255  255  255  255  255  255  255  255  ...   253   254   \n",
              "1982  metal  114  115  119  126  127  131  124  125  129  ...     4     7   \n",
              "1983  metal  221  221  219  221  221  219  220  220  218  ...   232   238   \n",
              "1984  metal  255  255  255  255  255  255  253  255  254  ...   238   254   \n",
              "1985  metal   98   99   81  116  117   99  122  119  102  ...   192   180   \n",
              "\n",
              "     B4089 B4090 B4091 B4092 B4093 B4094 B4095 B4096  \n",
              "0      255   255   252   255   255   252   255   255  \n",
              "1      253   253   253   253   253   253   253   253  \n",
              "2      159   171   162   162   172   165   165   175  \n",
              "3       72    51    91    60    42    82    53    35  \n",
              "4      191   193   195   186   187   192   183   184  \n",
              "...    ...   ...   ...   ...   ...   ...   ...   ...  \n",
              "1981   254   254   255   255   255   255   255   255  \n",
              "1982     3     4     7     3     4     7     3     4  \n",
              "1983   234   233   238   234   233   239   235   234  \n",
              "1984   255   255   250   254   253   252   255   255  \n",
              "1985   184   183   180   184   183   186   190   189  \n",
              "\n",
              "[1986 rows x 12289 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a7901859-be08-44be-81f8-485068fc94ed\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>R1</th>\n",
              "      <th>R2</th>\n",
              "      <th>R3</th>\n",
              "      <th>R4</th>\n",
              "      <th>R5</th>\n",
              "      <th>R6</th>\n",
              "      <th>R7</th>\n",
              "      <th>R8</th>\n",
              "      <th>R9</th>\n",
              "      <th>...</th>\n",
              "      <th>B4087</th>\n",
              "      <th>B4088</th>\n",
              "      <th>B4089</th>\n",
              "      <th>B4090</th>\n",
              "      <th>B4091</th>\n",
              "      <th>B4092</th>\n",
              "      <th>B4093</th>\n",
              "      <th>B4094</th>\n",
              "      <th>B4095</th>\n",
              "      <th>B4096</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>metal</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>...</td>\n",
              "      <td>255</td>\n",
              "      <td>254</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>252</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>252</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>metal</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>...</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>metal</td>\n",
              "      <td>220</td>\n",
              "      <td>221</td>\n",
              "      <td>239</td>\n",
              "      <td>220</td>\n",
              "      <td>221</td>\n",
              "      <td>239</td>\n",
              "      <td>219</td>\n",
              "      <td>220</td>\n",
              "      <td>238</td>\n",
              "      <td>...</td>\n",
              "      <td>169</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>171</td>\n",
              "      <td>162</td>\n",
              "      <td>162</td>\n",
              "      <td>172</td>\n",
              "      <td>165</td>\n",
              "      <td>165</td>\n",
              "      <td>175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>metal</td>\n",
              "      <td>159</td>\n",
              "      <td>112</td>\n",
              "      <td>60</td>\n",
              "      <td>163</td>\n",
              "      <td>115</td>\n",
              "      <td>66</td>\n",
              "      <td>170</td>\n",
              "      <td>118</td>\n",
              "      <td>71</td>\n",
              "      <td>...</td>\n",
              "      <td>60</td>\n",
              "      <td>104</td>\n",
              "      <td>72</td>\n",
              "      <td>51</td>\n",
              "      <td>91</td>\n",
              "      <td>60</td>\n",
              "      <td>42</td>\n",
              "      <td>82</td>\n",
              "      <td>53</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>metal</td>\n",
              "      <td>126</td>\n",
              "      <td>93</td>\n",
              "      <td>62</td>\n",
              "      <td>129</td>\n",
              "      <td>96</td>\n",
              "      <td>65</td>\n",
              "      <td>134</td>\n",
              "      <td>99</td>\n",
              "      <td>69</td>\n",
              "      <td>...</td>\n",
              "      <td>196</td>\n",
              "      <td>197</td>\n",
              "      <td>191</td>\n",
              "      <td>193</td>\n",
              "      <td>195</td>\n",
              "      <td>186</td>\n",
              "      <td>187</td>\n",
              "      <td>192</td>\n",
              "      <td>183</td>\n",
              "      <td>184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1981</th>\n",
              "      <td>metal</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>...</td>\n",
              "      <td>253</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1982</th>\n",
              "      <td>metal</td>\n",
              "      <td>114</td>\n",
              "      <td>115</td>\n",
              "      <td>119</td>\n",
              "      <td>126</td>\n",
              "      <td>127</td>\n",
              "      <td>131</td>\n",
              "      <td>124</td>\n",
              "      <td>125</td>\n",
              "      <td>129</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1983</th>\n",
              "      <td>metal</td>\n",
              "      <td>221</td>\n",
              "      <td>221</td>\n",
              "      <td>219</td>\n",
              "      <td>221</td>\n",
              "      <td>221</td>\n",
              "      <td>219</td>\n",
              "      <td>220</td>\n",
              "      <td>220</td>\n",
              "      <td>218</td>\n",
              "      <td>...</td>\n",
              "      <td>232</td>\n",
              "      <td>238</td>\n",
              "      <td>234</td>\n",
              "      <td>233</td>\n",
              "      <td>238</td>\n",
              "      <td>234</td>\n",
              "      <td>233</td>\n",
              "      <td>239</td>\n",
              "      <td>235</td>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1984</th>\n",
              "      <td>metal</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>253</td>\n",
              "      <td>255</td>\n",
              "      <td>254</td>\n",
              "      <td>...</td>\n",
              "      <td>238</td>\n",
              "      <td>254</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>250</td>\n",
              "      <td>254</td>\n",
              "      <td>253</td>\n",
              "      <td>252</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1985</th>\n",
              "      <td>metal</td>\n",
              "      <td>98</td>\n",
              "      <td>99</td>\n",
              "      <td>81</td>\n",
              "      <td>116</td>\n",
              "      <td>117</td>\n",
              "      <td>99</td>\n",
              "      <td>122</td>\n",
              "      <td>119</td>\n",
              "      <td>102</td>\n",
              "      <td>...</td>\n",
              "      <td>192</td>\n",
              "      <td>180</td>\n",
              "      <td>184</td>\n",
              "      <td>183</td>\n",
              "      <td>180</td>\n",
              "      <td>184</td>\n",
              "      <td>183</td>\n",
              "      <td>186</td>\n",
              "      <td>190</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1986 rows  12289 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7901859-be08-44be-81f8-485068fc94ed')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a7901859-be08-44be-81f8-485068fc94ed button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a7901859-be08-44be-81f8-485068fc94ed');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-be1b1856-20d9-44a7-a003-8061620ca2b7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-be1b1856-20d9-44a7-a003-8061620ca2b7')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-be1b1856-20d9-44a7-a003-8061620ca2b7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(data[data['label'] == 'metal'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCV_Y767kQCp"
      },
      "source": [
        "## *Train Test Splitting and Integer Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2rwHYrAjQNz",
        "outputId": "4c7af567-1478-4d57-bf58-ed9a281bd6d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape is: (6484, 12288)\n",
            "y_train shape is: (6484,)\n",
            "X_test shape is: (1622, 12288)\n",
            "y_test shape is: (1622,)\n"
          ]
        }
      ],
      "source": [
        "## Split into stratified train and test sets and Integer Encoding Labels into Integers\n",
        "label_mapping = {'metal': 0, 'glass': 1, 'paper': 2, 'plastic': 3}\n",
        "data['encoded_label'] = data['label'].map(label_mapping)\n",
        "columns_to_drop = ['label','encoded_label']\n",
        "\n",
        "y = data['encoded_label']\n",
        "X = data.drop(columns=columns_to_drop,axis=1)\n",
        "X = X.astype('float32') / 255.0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,stratify=y,random_state=0)\n",
        "print(f'X_train shape is: {X_train.shape}')\n",
        "print(f'y_train shape is: {y_train.shape}')\n",
        "print(f'X_test shape is: {X_test.shape}')\n",
        "print(f'y_test shape is: {y_test.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SuFvWSWvKb83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelling Using ML Models"
      ],
      "metadata": {
        "id": "InRmTxf5lYjN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *One-hot encoding Function"
      ],
      "metadata": {
        "id": "uvtOE--SBOA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## One hot encoding for y_pred and y_test\n",
        "def ohe_y(y):\n",
        "  n_classes = 4\n",
        "  y_reshaped = np.zeros((len(y),n_classes))\n",
        "  y_reshaped[np.arange(len(y)),y] = 1\n",
        "  return y_reshaped"
      ],
      "metadata": {
        "id": "4E7IasLIleRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo1QE13UkVA4"
      },
      "source": [
        "## Modelling Part I: KNN\n",
        "\n",
        "Results:\n",
        "\n",
        "32x32: 0.60543,0.73652,0.60526\n",
        "\n",
        "64x64: 0.59864, 0.73221,0.60058"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j59spc6dlOQJ",
        "outputId": "aa747bc5-63da-41c3-a4cd-281a57d836d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score is  0.59864\n",
            "ROC AUC score is  0.73221\n",
            "F1 score is  0.60058\n"
          ]
        }
      ],
      "source": [
        "# KNN\n",
        "\n",
        "model = KNeighborsClassifier(n_neighbors=5)\n",
        "model.fit(X_train,y_train)\n",
        "y_pred = (model.predict(X_test)).astype(int).flatten()\n",
        "\n",
        "accu_knn = accuracy_score(ohe_y(y_test),ohe_y(y_pred))\n",
        "roc_knn = roc_auc_score(ohe_y(y_test),ohe_y(y_pred),average='weighted',multi_class='ovo')\n",
        "f1_knn = f1_score(ohe_y(y_test),ohe_y(y_pred),average='weighted')\n",
        "\n",
        "print('Accuracy score is ', str(format(accu_knn,'.5f')))\n",
        "print('ROC AUC score is ', str(format(roc_knn,'.5f')))\n",
        "print('F1 score is ', str(format(f1_knn,'.5f')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg-GWdijtCty"
      },
      "source": [
        "## Modelling Part II: SVC\n",
        "\n",
        "Results:\n",
        "\n",
        "32x32: 0.59125,0.72865,0.59154\n",
        "\n",
        "64x64: 0.66954,0.78006,0.67030"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nI53wGG6tGLe",
        "outputId": "cfbbf41f-92c6-439f-d5f0-1078497a14e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score is  0.66954\n",
            "ROC AUC score is  0.78006\n",
            "F1 score is  0.67030\n"
          ]
        }
      ],
      "source": [
        "# SVC\n",
        "\n",
        "model = SVC(kernel='linear',C=1,\n",
        "            # decision_function='ovo'\n",
        "            )\n",
        "model.fit(X_train,y_train)\n",
        "y_pred = (model.predict(X_test)).astype(int).flatten()\n",
        "\n",
        "accu_svc = accuracy_score(ohe_y(y_test),ohe_y(y_pred))\n",
        "roc_svc = roc_auc_score(ohe_y(y_test),ohe_y(y_pred),average='weighted',multi_class='ovo')\n",
        "f1_svc = f1_score(ohe_y(y_test),ohe_y(y_pred),average='weighted')\n",
        "\n",
        "print('Accuracy score is ', str(format(accu_svc,'.5f')))\n",
        "print('ROC AUC score is ', str(format(roc_svc,'.5f')))\n",
        "print('F1 score is ', str(format(f1_svc,'.5f')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM-2TlB6tY1n"
      },
      "source": [
        "## Modelling Part III: Catboost\n",
        "\n",
        "Results:\n",
        "\n",
        "32x32: 0.82491,0.88258,0.82421\n",
        "\n",
        "64x64: 0.82614,0.88319,0.82554"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BN6ZbuKStcR1",
        "outputId": "0e23bd33-ce95-4dbe-a070-4495e4d15bad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score is  0.82614\n",
            "ROC AUC score is  0.88319\n",
            "F1 score is  0.82554\n"
          ]
        }
      ],
      "source": [
        "# Catboost\n",
        "\n",
        "model = catboost.CatBoostClassifier(loss_function='MultiClass',one_hot_max_size=4,random_state=0,verbose=False)\n",
        "model.fit(X_train,y_train)\n",
        "y_pred = (model.predict(X_test)).astype(int).flatten()\n",
        "\n",
        "accu_cb = accuracy_score(ohe_y(y_test),ohe_y(y_pred))\n",
        "roc_cb = roc_auc_score(ohe_y(y_test),ohe_y(y_pred),average='weighted',multi_class='ovo')\n",
        "f1_cb = f1_score(ohe_y(y_test),ohe_y(y_pred),average='weighted')\n",
        "\n",
        "print('Accuracy score is ', str(format(accu_cb,'.5f')))\n",
        "print('ROC AUC score is ', str(format(roc_cb,'.5f')))\n",
        "print('F1 score is ', str(format(f1_cb,'.5f')))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelling using Deep Learning\n",
        "\n"
      ],
      "metadata": {
        "id": "WyxKJ4c2BX66"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Reshape Data for CNN"
      ],
      "metadata": {
        "id": "cHS_ZhvLTDoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rd = 64 #resize_dimension\n",
        "\n",
        "X_train_pixel_data = X_train.values\n",
        "X_test_pixel_data = X_test.values\n",
        "X_train_reshaped = (X_train_pixel_data.reshape(-1,rd,rd,3)).astype('float32')\n",
        "X_test_reshaped = (X_test_pixel_data.reshape(-1,rd,rd,3)).astype('float32')\n",
        "print(X_train_reshaped.shape)\n",
        "print(X_test_reshaped.shape)\n",
        "\n",
        "hi = ohe_y(y_train)\n",
        "ho = ohe_y(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQW8LvlxTFdD",
        "outputId": "6ab09862-984e-40c4-be4f-8a0681b81021"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6484, 64, 64, 3)\n",
            "(1622, 64, 64, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple CNN Architecture 1.1\n",
        "\n",
        "For starters, I used a simple CNN architecture which is used for identifying and classifying images. Using tensorflow, I created a 5 layer neural network.\n",
        "\n",
        "The first 3 layers consist of 3 layers that combine a convolutional layer and a pooling layer. The convolutional layer serves to process input data and identify simple patterns such as edges or gradients in the images. The pooling layer then retains the most important information while reducing the spatial dimensions of the output.\n",
        "\n",
        "The 4th layer flattens the output and turns into a 1D vector that can be fed into the next few layers.\n",
        "\n",
        "The 5th layer is a dense layer that focuses on making predictions from the output.\n",
        "\n",
        "The final output layer outputs the predicted class probabilities and then chooses the one with the highest probability as its predicted label.\n",
        "\n",
        "The final values from fitting the model are:\n",
        "\n",
        "\n",
        "```\n",
        "32x32: loss: 0.1878 - accuracy: 0.9337 - val_loss: 1.5473 - val_accuracy: 0.7244\n",
        "\n",
        "64x64:loss: 0.1364 - accuracy: 0.9664 - val_loss: 2.8081 - val_accuracy: 0.6905 (best was 0.7355)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "We can see that the train accuracy is high and close to 1 but the validation accuracy is far from that. This hints that the model is fitting well to the train data but not the test data, which means that our model may have a high variance issue.\n",
        "\n",
        "Furthermore, increasing image dimensions actually decreases the val accuracy which means the model is highly overfitted. For that we shall tweak the architecture a bit."
      ],
      "metadata": {
        "id": "XT75OOFHD4S8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Simple CNN Architecture 1.1\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.activations import relu, linear\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "#Convolutional Layer 1\n",
        "model.add(layers.Conv2D(16,(3,3),activation='relu',input_shape=(rd,rd,3)))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "\n",
        "#Convolutional Layer 2\n",
        "model.add(layers.Conv2D(32,(3,3),activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "\n",
        "#Convolutional Layer 3\n",
        "model.add(layers.Conv2D(32,(3,3),activation='relu'))\n",
        "\n",
        "#Layer 4 Flatten\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "#Layer 5 Fully connected\n",
        "model.add(layers.Dense(32,activation='relu'))\n",
        "model.add(layers.Dense(4,activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.fit(x=X_train_reshaped,\n",
        "          y=hi,\n",
        "          batch_size=32,\n",
        "          epochs=50,\n",
        "          validation_data=(X_test_reshaped,ho),\n",
        "          )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Aes7fMXEMYq",
        "outputId": "b30ca354-ae89-43b6-8097-bfc3fd862da8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 62, 62, 16)        448       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 31, 31, 16)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 29, 29, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 14, 14, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 12, 12, 32)        9248      \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 4608)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                147488    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 132       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 161956 (632.64 KB)\n",
            "Trainable params: 161956 (632.64 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "203/203 [==============================] - 9s 35ms/step - loss: 2.5670 - accuracy: 0.4092 - val_loss: 1.2214 - val_accuracy: 0.4112\n",
            "Epoch 2/50\n",
            "203/203 [==============================] - 6s 29ms/step - loss: 1.1284 - accuracy: 0.5108 - val_loss: 1.1003 - val_accuracy: 0.5296\n",
            "Epoch 3/50\n",
            "203/203 [==============================] - 6s 31ms/step - loss: 0.9627 - accuracy: 0.5975 - val_loss: 1.0978 - val_accuracy: 0.5808\n",
            "Epoch 4/50\n",
            "203/203 [==============================] - 6s 30ms/step - loss: 0.8212 - accuracy: 0.6687 - val_loss: 0.9734 - val_accuracy: 0.6467\n",
            "Epoch 5/50\n",
            "203/203 [==============================] - 6s 30ms/step - loss: 0.6876 - accuracy: 0.7295 - val_loss: 0.9872 - val_accuracy: 0.6806\n",
            "Epoch 6/50\n",
            "203/203 [==============================] - 6s 30ms/step - loss: 0.5458 - accuracy: 0.7940 - val_loss: 0.9573 - val_accuracy: 0.6603\n",
            "Epoch 7/50\n",
            "203/203 [==============================] - 6s 30ms/step - loss: 0.4479 - accuracy: 0.8291 - val_loss: 1.0739 - val_accuracy: 0.6769\n",
            "Epoch 8/50\n",
            "203/203 [==============================] - 6s 31ms/step - loss: 0.4097 - accuracy: 0.8472 - val_loss: 1.0327 - val_accuracy: 0.6825\n",
            "Epoch 9/50\n",
            "203/203 [==============================] - 6s 30ms/step - loss: 0.3201 - accuracy: 0.8808 - val_loss: 1.2143 - val_accuracy: 0.6991\n",
            "Epoch 10/50\n",
            "203/203 [==============================] - 6s 31ms/step - loss: 0.2704 - accuracy: 0.8981 - val_loss: 1.2974 - val_accuracy: 0.6819\n",
            "Epoch 11/50\n",
            "203/203 [==============================] - 6s 30ms/step - loss: 0.2739 - accuracy: 0.8971 - val_loss: 1.3633 - val_accuracy: 0.7084\n",
            "Epoch 12/50\n",
            "203/203 [==============================] - 7s 35ms/step - loss: 0.1875 - accuracy: 0.9323 - val_loss: 1.4490 - val_accuracy: 0.7109\n",
            "Epoch 13/50\n",
            "203/203 [==============================] - 6s 29ms/step - loss: 0.2273 - accuracy: 0.9213 - val_loss: 1.5858 - val_accuracy: 0.7090\n",
            "Epoch 14/50\n",
            "203/203 [==============================] - 6s 31ms/step - loss: 0.2001 - accuracy: 0.9301 - val_loss: 1.6012 - val_accuracy: 0.7170\n",
            "Epoch 15/50\n",
            "203/203 [==============================] - 6s 29ms/step - loss: 0.2047 - accuracy: 0.9320 - val_loss: 1.4913 - val_accuracy: 0.7115\n",
            "Epoch 16/50\n",
            "203/203 [==============================] - 6s 30ms/step - loss: 0.1492 - accuracy: 0.9505 - val_loss: 1.6360 - val_accuracy: 0.7041\n",
            "Epoch 17/50\n",
            "203/203 [==============================] - 7s 35ms/step - loss: 0.1947 - accuracy: 0.9315 - val_loss: 1.7317 - val_accuracy: 0.7078\n",
            "Epoch 18/50\n",
            "203/203 [==============================] - 6s 31ms/step - loss: 0.1783 - accuracy: 0.9405 - val_loss: 1.9202 - val_accuracy: 0.7004\n",
            "Epoch 19/50\n",
            "203/203 [==============================] - 6s 31ms/step - loss: 0.1012 - accuracy: 0.9638 - val_loss: 2.0261 - val_accuracy: 0.7232\n",
            "Epoch 20/50\n",
            "203/203 [==============================] - 6s 31ms/step - loss: 0.0931 - accuracy: 0.9673 - val_loss: 2.0881 - val_accuracy: 0.7318\n",
            "Epoch 21/50\n",
            "203/203 [==============================] - 6s 31ms/step - loss: 0.0556 - accuracy: 0.9821 - val_loss: 2.2579 - val_accuracy: 0.7145\n",
            "Epoch 22/50\n",
            "203/203 [==============================] - 6s 29ms/step - loss: 0.0829 - accuracy: 0.9716 - val_loss: 2.6346 - val_accuracy: 0.7022\n",
            "Epoch 23/50\n",
            "203/203 [==============================] - 6s 31ms/step - loss: 0.1407 - accuracy: 0.9554 - val_loss: 2.3691 - val_accuracy: 0.6930\n",
            "Epoch 24/50\n",
            "203/203 [==============================] - 6s 29ms/step - loss: 0.2018 - accuracy: 0.9374 - val_loss: 2.2231 - val_accuracy: 0.7016\n",
            "Epoch 25/50\n",
            "203/203 [==============================] - 6s 30ms/step - loss: 0.1340 - accuracy: 0.9537 - val_loss: 2.2875 - val_accuracy: 0.7201\n",
            "Epoch 26/50\n",
            "203/203 [==============================] - 6s 30ms/step - loss: 0.0873 - accuracy: 0.9750 - val_loss: 2.2301 - val_accuracy: 0.7392\n",
            "Epoch 27/50\n",
            "203/203 [==============================] - 6s 30ms/step - loss: 0.0681 - accuracy: 0.9783 - val_loss: 2.1088 - val_accuracy: 0.7226\n",
            "Epoch 28/50\n",
            "203/203 [==============================] - 6s 31ms/step - loss: 0.0972 - accuracy: 0.9710 - val_loss: 2.2958 - val_accuracy: 0.6998\n",
            "Epoch 29/50\n",
            "203/203 [==============================] - 6s 29ms/step - loss: 0.0633 - accuracy: 0.9783 - val_loss: 2.4045 - val_accuracy: 0.7238\n",
            "Epoch 30/50\n",
            "203/203 [==============================] - 6s 32ms/step - loss: 0.0943 - accuracy: 0.9701 - val_loss: 2.4558 - val_accuracy: 0.7041\n",
            "Epoch 31/50\n",
            "203/203 [==============================] - 6s 29ms/step - loss: 0.1276 - accuracy: 0.9601 - val_loss: 2.4197 - val_accuracy: 0.7121\n",
            "Epoch 32/50\n",
            "203/203 [==============================] - 6s 31ms/step - loss: 0.1219 - accuracy: 0.9627 - val_loss: 2.3557 - val_accuracy: 0.7152\n",
            "Epoch 33/50\n",
            "203/203 [==============================] - 6s 29ms/step - loss: 0.1509 - accuracy: 0.9590 - val_loss: 2.5791 - val_accuracy: 0.6998\n",
            "Epoch 34/50\n",
            "203/203 [==============================] - 6s 30ms/step - loss: 0.0929 - accuracy: 0.9721 - val_loss: 2.4697 - val_accuracy: 0.7127\n",
            "Epoch 35/50\n",
            "203/203 [==============================] - 6s 30ms/step - loss: 0.0815 - accuracy: 0.9772 - val_loss: 2.5165 - val_accuracy: 0.7158\n",
            "Epoch 36/50\n",
            "203/203 [==============================] - 6s 29ms/step - loss: 0.0582 - accuracy: 0.9806 - val_loss: 2.6707 - val_accuracy: 0.7355\n",
            "Epoch 37/50\n",
            "203/203 [==============================] - 6s 31ms/step - loss: 0.0391 - accuracy: 0.9881 - val_loss: 2.8198 - val_accuracy: 0.7355\n",
            "Epoch 38/50\n",
            "203/203 [==============================] - 6s 29ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 3.0020 - val_accuracy: 0.7189\n",
            "Epoch 39/50\n",
            "203/203 [==============================] - 6s 31ms/step - loss: 0.1344 - accuracy: 0.9628 - val_loss: 2.7696 - val_accuracy: 0.7035\n",
            "Epoch 40/50\n",
            "203/203 [==============================] - 6s 29ms/step - loss: 0.1007 - accuracy: 0.9704 - val_loss: 2.7896 - val_accuracy: 0.7238\n",
            "Epoch 41/50\n",
            "203/203 [==============================] - 6s 30ms/step - loss: 0.1415 - accuracy: 0.9625 - val_loss: 2.5672 - val_accuracy: 0.7300\n",
            "Epoch 42/50\n",
            "203/203 [==============================] - 6s 30ms/step - loss: 0.0508 - accuracy: 0.9847 - val_loss: 2.7941 - val_accuracy: 0.7115\n",
            "Epoch 43/50\n",
            "203/203 [==============================] - 6s 29ms/step - loss: 0.0912 - accuracy: 0.9727 - val_loss: 2.8393 - val_accuracy: 0.7127\n",
            "Epoch 44/50\n",
            "203/203 [==============================] - 6s 30ms/step - loss: 0.0710 - accuracy: 0.9770 - val_loss: 2.9157 - val_accuracy: 0.7374\n",
            "Epoch 45/50\n",
            "203/203 [==============================] - 6s 29ms/step - loss: 0.0343 - accuracy: 0.9889 - val_loss: 2.9773 - val_accuracy: 0.7275\n",
            "Epoch 46/50\n",
            "203/203 [==============================] - 6s 30ms/step - loss: 0.1393 - accuracy: 0.9621 - val_loss: 2.6343 - val_accuracy: 0.6991\n",
            "Epoch 47/50\n",
            "203/203 [==============================] - 6s 29ms/step - loss: 0.0881 - accuracy: 0.9732 - val_loss: 2.8069 - val_accuracy: 0.7219\n",
            "Epoch 48/50\n",
            "203/203 [==============================] - 6s 30ms/step - loss: 0.0208 - accuracy: 0.9928 - val_loss: 3.0923 - val_accuracy: 0.7324\n",
            "Epoch 49/50\n",
            "203/203 [==============================] - 6s 29ms/step - loss: 0.0196 - accuracy: 0.9944 - val_loss: 3.6859 - val_accuracy: 0.7219\n",
            "Epoch 50/50\n",
            "203/203 [==============================] - 6s 29ms/step - loss: 0.1364 - accuracy: 0.9664 - val_loss: 2.8081 - val_accuracy: 0.6905\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e956dd88730>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple CNN Architecture 1.2\n",
        "\n",
        "### High Variance and Regularization\n",
        "\n",
        "For tweaking our architecture, we shall focus on reducing overfitting and getting rid of high variance.\n",
        "\n",
        "Firstly, we shall reduce model's complexity by lowering the number of filters in each convolutional layer. We shall cut each layer's filters by half.We shall do this for the dense layer neurons as well.\n",
        "\n",
        "Next, we shall add a dropout layer after the first dense layer, whcih randomly deactivates the neurons of this dense layer to prevent overfitting by preventing reliance on any particular set of neurons. We will set 0.5 as the fraction of neurons to drop for starters\n",
        "\n",
        "For the third tweak, we would be adding early stopping to monitor models' validation accuracy and stopping the model when it no longer shows improvement, to find the optimal epoch number and prevent overfitting. We shall start with a small patience value at 10 for now.\n",
        "\n",
        "Next, we will be extending the number of epochs since we are implementing many regularization techniques.\n",
        "\n",
        "`Epoch 28 64x64: loss: 1.3811 - accuracy: 0.2839 - val_loss: 1.3809 - val_accuracy: 0.2842`\n",
        "\n",
        "Seems like we have regularized too much. Let us reset the number of filters and dense layer neurons. We will keep dropout and early stopping and epoch number."
      ],
      "metadata": {
        "id": "ZVm8_txyZKLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Simple CNN Architecture 1.2\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.activations import relu, linear\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss',\n",
        "                               patience=10,\n",
        "                               restore_best_weights=True)\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "#Convolutional Layer 1\n",
        "model.add(layers.Conv2D(8,(3,3),activation='relu',input_shape=(rd,rd,3)))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "\n",
        "#Convolutional Layer 2\n",
        "model.add(layers.Conv2D(16,(3,3),activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "\n",
        "#Convolutional Layer 3\n",
        "model.add(layers.Conv2D(16,(3,3),activation='relu'))\n",
        "\n",
        "#Layer 4 Flatten\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "#Layer 5 Fully connected\n",
        "model.add(layers.Dense(16,activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "model.add(layers.Dense(4,activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.fit(x=X_train_reshaped,\n",
        "          y=hi,\n",
        "          batch_size=32,\n",
        "          epochs=100,\n",
        "          validation_data=(X_test_reshaped,ho),\n",
        "          callbacks=[early_stopping]\n",
        "          )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhNLSbTEZjQC",
        "outputId": "fd00e18e-3796-452e-e83c-f19d5deb4028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (None, 62, 62, 8)         224       \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 31, 31, 8)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 29, 29, 16)        1168      \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 14, 14, 16)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 12, 12, 16)        2320      \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 2304)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 16)                36880     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 40660 (158.83 KB)\n",
            "Trainable params: 40660 (158.83 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "203/203 [==============================] - 6s 24ms/step - loss: 1.6336 - accuracy: 0.2773 - val_loss: 1.3827 - val_accuracy: 0.2842\n",
            "Epoch 2/50\n",
            "203/203 [==============================] - 4s 22ms/step - loss: 1.3821 - accuracy: 0.2839 - val_loss: 1.3814 - val_accuracy: 0.2842\n",
            "Epoch 3/50\n",
            "203/203 [==============================] - 5s 23ms/step - loss: 1.3815 - accuracy: 0.2839 - val_loss: 1.3811 - val_accuracy: 0.2842\n",
            "Epoch 4/50\n",
            "203/203 [==============================] - 4s 22ms/step - loss: 1.3812 - accuracy: 0.2839 - val_loss: 1.3810 - val_accuracy: 0.2842\n",
            "Epoch 5/50\n",
            "203/203 [==============================] - 4s 22ms/step - loss: 1.3812 - accuracy: 0.2839 - val_loss: 1.3810 - val_accuracy: 0.2842\n",
            "Epoch 6/50\n",
            "203/203 [==============================] - 5s 23ms/step - loss: 1.3811 - accuracy: 0.2839 - val_loss: 1.3809 - val_accuracy: 0.2842\n",
            "Epoch 7/50\n",
            "203/203 [==============================] - 4s 22ms/step - loss: 1.3812 - accuracy: 0.2839 - val_loss: 1.3809 - val_accuracy: 0.2842\n",
            "Epoch 8/50\n",
            "203/203 [==============================] - 4s 22ms/step - loss: 1.3811 - accuracy: 0.2839 - val_loss: 1.3809 - val_accuracy: 0.2842\n",
            "Epoch 9/50\n",
            "203/203 [==============================] - 5s 24ms/step - loss: 1.3811 - accuracy: 0.2839 - val_loss: 1.3809 - val_accuracy: 0.2842\n",
            "Epoch 10/50\n",
            "203/203 [==============================] - 5s 22ms/step - loss: 1.3811 - accuracy: 0.2839 - val_loss: 1.3809 - val_accuracy: 0.2842\n",
            "Epoch 11/50\n",
            "203/203 [==============================] - 4s 22ms/step - loss: 1.3811 - accuracy: 0.2839 - val_loss: 1.3809 - val_accuracy: 0.2842\n",
            "Epoch 12/50\n",
            "203/203 [==============================] - 5s 23ms/step - loss: 1.3812 - accuracy: 0.2839 - val_loss: 1.3809 - val_accuracy: 0.2842\n",
            "Epoch 13/50\n",
            "203/203 [==============================] - 5s 22ms/step - loss: 1.3811 - accuracy: 0.2839 - val_loss: 1.3809 - val_accuracy: 0.2842\n",
            "Epoch 14/50\n",
            "203/203 [==============================] - 4s 22ms/step - loss: 1.3812 - accuracy: 0.2839 - val_loss: 1.3809 - val_accuracy: 0.2842\n",
            "Epoch 15/50\n",
            "203/203 [==============================] - 5s 23ms/step - loss: 1.3811 - accuracy: 0.2839 - val_loss: 1.3809 - val_accuracy: 0.2842\n",
            "Epoch 16/50\n",
            "203/203 [==============================] - 5s 23ms/step - loss: 1.3811 - accuracy: 0.2839 - val_loss: 1.3809 - val_accuracy: 0.2842\n",
            "Epoch 17/50\n",
            "203/203 [==============================] - 5s 25ms/step - loss: 1.3812 - accuracy: 0.2839 - val_loss: 1.3809 - val_accuracy: 0.2842\n",
            "Epoch 18/50\n",
            "203/203 [==============================] - 5s 24ms/step - loss: 1.3812 - accuracy: 0.2839 - val_loss: 1.3809 - val_accuracy: 0.2842\n",
            "Epoch 19/50\n",
            "203/203 [==============================] - 4s 22ms/step - loss: 1.3812 - accuracy: 0.2839 - val_loss: 1.3809 - val_accuracy: 0.2842\n",
            "Epoch 20/50\n",
            "203/203 [==============================] - 5s 22ms/step - loss: 1.3811 - accuracy: 0.2839 - val_loss: 1.3809 - val_accuracy: 0.2842\n",
            "Epoch 21/50\n",
            "203/203 [==============================] - 5s 24ms/step - loss: 1.3812 - accuracy: 0.2839 - val_loss: 1.3809 - val_accuracy: 0.2842\n",
            "Epoch 22/50\n",
            "203/203 [==============================] - 4s 22ms/step - loss: 1.3812 - accuracy: 0.2839 - val_loss: 1.3809 - val_accuracy: 0.2842\n",
            "Epoch 23/50\n",
            "203/203 [==============================] - 4s 22ms/step - loss: 1.3812 - accuracy: 0.2839 - val_loss: 1.3809 - val_accuracy: 0.2842\n",
            "Epoch 24/50\n",
            "203/203 [==============================] - 5s 24ms/step - loss: 1.3812 - accuracy: 0.2839 - val_loss: 1.3809 - val_accuracy: 0.2842\n",
            "Epoch 25/50\n",
            "203/203 [==============================] - 4s 22ms/step - loss: 1.3811 - accuracy: 0.2839 - val_loss: 1.3809 - val_accuracy: 0.2842\n",
            "Epoch 26/50\n",
            "203/203 [==============================] - 4s 22ms/step - loss: 1.3812 - accuracy: 0.2839 - val_loss: 1.3809 - val_accuracy: 0.2842\n",
            "Epoch 27/50\n",
            "203/203 [==============================] - 5s 23ms/step - loss: 1.3812 - accuracy: 0.2839 - val_loss: 1.3809 - val_accuracy: 0.2842\n",
            "Epoch 28/50\n",
            "203/203 [==============================] - 4s 22ms/step - loss: 1.3811 - accuracy: 0.2839 - val_loss: 1.3809 - val_accuracy: 0.2842\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e95aaf7bdc0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple CNN Architecture 1.3\n",
        "\n",
        "### Choosing Optimal Dropout Fraction\n",
        "`Epoch 20 64x64:loss: 1.3811 - accuracy: 0.2839 - val_loss: 1.3809 - val_accuracy: 0.2842`\n",
        "\n",
        "No change at all. We shall temporarily switch off the dropout layer and see whether it's because it's too big.\n",
        "\n",
        "`Epoch 17 64x64 loss: 0.2398 - accuracy: 0.9133 - val_loss: 1.7411 - val_accuracy: 0.6726`\n",
        "\n",
        "We will now try different fractions of dropout and pick the best one:\n",
        "\n",
        "```\n",
        "0.0: loss: 0.2398 - accuracy: 0.9133 - val_loss: 1.7411 - val_accuracy: 0.6726\n",
        "\n",
        "0.1: loss: 0.3475 - accuracy: 0.8612 - val_loss: 0.9990 - val_accuracy: 0.7022\n",
        "\n",
        "0.2: loss: 1.3812 - accuracy: 0.2839 - val_loss: 1.3809 - val_accuracy: 0.2842\n",
        "\n",
        "0.15: loss: 0.2624 - accuracy: 0.8927 - val_loss: 1.2451 - val_accuracy: 0.7324\n",
        "\n",
        "0.175: loss: 1.3812 - accuracy: 0.2839 - val_loss: 1.3809 - val_accuracy: 0.284\n",
        "\n",
        "0.1625: loss: 0.4614 - accuracy: 0.8117 - val_loss: 1.1683 - val_accuracy: 0.7145\n",
        "\n",
        "0.15625: loss: 0.3273 - accuracy: 0.8695 - val_loss: 1.1305 - val_accuracy: 0.6930\n",
        "\n",
        "0.16875: loss: 0.2978 - accuracy: 0.8871 - val_loss: 1.2931 - val_accuracy: 0.7232\n",
        "\n",
        "0.165625: loss: 0.3475 - accuracy: 0.8712 - val_loss: 1.2771 - val_accuracy: 0.6954\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "0.1625 dropout fraction seems to be the best due to the smallest difference between accuracies as well as being high relatively values. Also, the validation loss is on the better end. 0.15625 is a big contender as well but a higher dropout fraction is better to combat overfitting."
      ],
      "metadata": {
        "id": "guYtgqfAff3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Simple CNN Architecture 1.3\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.activations import relu, linear\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss',\n",
        "                               patience=10,\n",
        "                               restore_best_weights=True)\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "#Convolutional Layer 1\n",
        "model.add(layers.Conv2D(16,(3,3),activation='relu',input_shape=(rd,rd,3)))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "\n",
        "#Convolutional Layer 2\n",
        "model.add(layers.Conv2D(32,(3,3),activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "\n",
        "#Convolutional Layer 3\n",
        "model.add(layers.Conv2D(32,(3,3),activation='relu'))\n",
        "\n",
        "#Layer 4 Flatten\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "#Layer 5 Fully connected\n",
        "model.add(layers.Dense(32,activation='relu'))\n",
        "model.add(layers.Dropout(0.1625))\n",
        "\n",
        "# Layer 6 Prediction\n",
        "model.add(layers.Dense(4,activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.fit(x=X_train_reshaped,\n",
        "          y=hi,\n",
        "          batch_size=32,\n",
        "          epochs=100,\n",
        "          validation_data=(X_test_reshaped,ho),\n",
        "          callbacks=[early_stopping]\n",
        "          )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0B9MYYDLfiZT",
        "outputId": "ea0d96e0-88b4-4b8b-9af4-0ea975a41ee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_39 (Conv2D)          (None, 62, 62, 16)        448       \n",
            "                                                                 \n",
            " max_pooling2d_26 (MaxPooli  (None, 31, 31, 16)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_40 (Conv2D)          (None, 29, 29, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_27 (MaxPooli  (None, 14, 14, 32)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_41 (Conv2D)          (None, 12, 12, 32)        9248      \n",
            "                                                                 \n",
            " flatten_13 (Flatten)        (None, 4608)              0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 32)                147488    \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 4)                 132       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 161956 (632.64 KB)\n",
            "Trainable params: 161956 (632.64 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "203/203 [==============================] - 7s 31ms/step - loss: 2.4351 - accuracy: 0.3637 - val_loss: 1.2663 - val_accuracy: 0.4433\n",
            "Epoch 2/100\n",
            "203/203 [==============================] - 6s 30ms/step - loss: 1.2317 - accuracy: 0.4326 - val_loss: 1.2169 - val_accuracy: 0.4784\n",
            "Epoch 3/100\n",
            "203/203 [==============================] - 6s 29ms/step - loss: 1.1072 - accuracy: 0.5094 - val_loss: 1.1818 - val_accuracy: 0.5105\n",
            "Epoch 4/100\n",
            "203/203 [==============================] - 6s 31ms/step - loss: 1.0000 - accuracy: 0.5774 - val_loss: 1.0608 - val_accuracy: 0.5617\n",
            "Epoch 5/100\n",
            "203/203 [==============================] - 6s 29ms/step - loss: 0.8723 - accuracy: 0.6359 - val_loss: 1.0874 - val_accuracy: 0.6030\n",
            "Epoch 6/100\n",
            "203/203 [==============================] - 6s 31ms/step - loss: 0.8037 - accuracy: 0.6656 - val_loss: 1.0447 - val_accuracy: 0.6054\n",
            "Epoch 7/100\n",
            "203/203 [==============================] - 6s 29ms/step - loss: 0.7229 - accuracy: 0.7108 - val_loss: 1.0661 - val_accuracy: 0.6134\n",
            "Epoch 8/100\n",
            "203/203 [==============================] - 6s 30ms/step - loss: 0.6370 - accuracy: 0.7478 - val_loss: 1.1493 - val_accuracy: 0.6141\n",
            "Epoch 9/100\n",
            "203/203 [==============================] - 6s 30ms/step - loss: 0.5552 - accuracy: 0.7796 - val_loss: 1.0518 - val_accuracy: 0.6646\n",
            "Epoch 10/100\n",
            "203/203 [==============================] - 6s 30ms/step - loss: 0.5010 - accuracy: 0.8043 - val_loss: 1.1377 - val_accuracy: 0.6689\n",
            "Epoch 11/100\n",
            "203/203 [==============================] - 6s 31ms/step - loss: 0.4687 - accuracy: 0.8194 - val_loss: 1.1753 - val_accuracy: 0.6677\n",
            "Epoch 12/100\n",
            "203/203 [==============================] - 6s 29ms/step - loss: 0.4485 - accuracy: 0.8208 - val_loss: 1.2197 - val_accuracy: 0.6825\n",
            "Epoch 13/100\n",
            "203/203 [==============================] - 6s 31ms/step - loss: 0.4156 - accuracy: 0.8410 - val_loss: 1.4257 - val_accuracy: 0.6529\n",
            "Epoch 14/100\n",
            "203/203 [==============================] - 6s 29ms/step - loss: 0.3941 - accuracy: 0.8496 - val_loss: 1.2401 - val_accuracy: 0.6942\n",
            "Epoch 15/100\n",
            "203/203 [==============================] - 6s 31ms/step - loss: 0.3620 - accuracy: 0.8683 - val_loss: 1.3085 - val_accuracy: 0.6825\n",
            "Epoch 16/100\n",
            "203/203 [==============================] - 6s 29ms/step - loss: 0.3475 - accuracy: 0.8712 - val_loss: 1.2771 - val_accuracy: 0.6954\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e9583f4d390>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple CNN Architecture 1.4\n",
        "\n",
        "### Increasing Model Complexity\n",
        "\n",
        "Now that we have cleared the high variance issue with dropout and early stopping, we have to deal with increasing the train and validation accuracies by increasing the model's complexity. For starters, we shall double convolutional filters and dense neurons.\n",
        "```\n",
        "32,32,64,64,64: loss: 1.3812 - accuracy: 0.2839 - val_loss: 1.3809 - val_accuracy: 0.2842\n",
        "32,32,64,128,64: loss: 0.1534 - accuracy: 0.9459 - val_loss: 1.4052 - val_accuracy: 0.7417\n",
        "32,32,64,128,64: loss: 0.2271 - accuracy: 0.9206 - val_loss: 1.1634 - val_accuracy: 0.7398\n",
        "32,32,64p,64,64: loss: 0.3224 - accuracy: 0.8828 - val_loss: 0.9715 - val_accuracy: 0.7497\n",
        "\n",
        "32,32,64p,128p,64: loss: 0.1890 - accuracy: 0.9321 - val_loss: 1.1251 - val_accuracy: 0.7700\n",
        "32,32,64p,128p,64,DF0.325: loss: 0.3251 - accuracy: 0.8794 - val_loss: 0.8978 - val_accuracy: 0.7731\n",
        "32,64,64p,128p,64,DF0.4 loss: 0.2900 - accuracy: 0.8970 - val_loss: 0.9962 - val_accuracy: 0.7855\n",
        "32,64p,64p,128p,64,DF0.5: loss: 1.3812 - accuracy: 0.2839 - val_loss: 1.3809 - val_accuracy: 0.2842\n",
        "32p,64p,64p,128p,64,DF0.45: loss: 0.3017 - accuracy: 0.8899 - val_loss: 0.8716 - val_accuracy: 0.7805\n",
        "32p,64p,64p,128p,64,DF0.425: loss: 0.2627 - accuracy: 0.9035 - val_loss: 0.9003 - val_accuracy: 0.7454\n",
        "```\n",
        "0.4 and 0.45 dropout fraction seems promising. Now we shall try with batch normalisation.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "32,32,64p,64,64: loss: 0.0833 - accuracy: 0.9696 - val_loss: 0.9244 - val_accuracy: 0.7805\n",
        "32p,32p,64p,128p,64: loss: 0.1430 - accuracy: 0.9477 - val_loss: 0.9373 - val_accuracy: 0.7848\n",
        "32p,64p,64p,128p,64,DF0.325: loss: 0.0591 - accuracy: 0.9795 - val_loss: 0.8512 - val_accuracy: 0.7965\n",
        "32p,64p,64p,128p,64,DF0.4: loss: 0.0895 - accuracy: 0.9692 - val_loss: 1.0204 - val_accuracy: 0.7540\n",
        "32p,64p,64p,128p,64,DF0.5: loss: 0.1088 - accuracy: 0.9624 - val_loss: 0.8020 - val_accuracy: 0.7811\n",
        "32p,64p,64p,128p,64,DF0.45: loss: 0.0833 - accuracy: 0.9716 - val_loss: 1.1734 - val_accuracy: 0.7244\n",
        "32p,64p,64p,128p,64,DF0.425: loss: 0.0855 - accuracy: 0.9718 - val_loss: 0.8041 - val_accuracy: 0.8033\n",
        "```\n",
        "\n",
        "0.425 DF seems to work the best so we'll go with that for now.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8kDT5ojTvcgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Simple CNN Architecture 1.4\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.activations import relu, linear\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss',\n",
        "                               patience=10,\n",
        "                               restore_best_weights=True)\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "#Convolutional Layer 1\n",
        "model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(rd,rd,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "\n",
        "#Convolutional Layer 2\n",
        "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "\n",
        "#Convolutional Layer 3\n",
        "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "\n",
        "#Convolutional Layer 4\n",
        "model.add(layers.Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "\n",
        "#Layer 5 Flatten\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "#Layer 6 Fully connected\n",
        "model.add(layers.Dense(64,activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.425))\n",
        "\n",
        "# Layer 7 Prediction\n",
        "model.add(layers.Dense(4,activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.fit(x=X_train_reshaped,\n",
        "          y=hi,\n",
        "          batch_size=32,\n",
        "          epochs=100,\n",
        "          validation_data=(X_test_reshaped,ho),\n",
        "          callbacks=[early_stopping]\n",
        "          )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oU6-ron5jqB6",
        "outputId": "31117017-8809-4e70-dcf7-17012e8807ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_109 (Conv2D)         (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_35 (Ba  (None, 62, 62, 32)        128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_88 (MaxPooli  (None, 31, 31, 32)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_110 (Conv2D)         (None, 29, 29, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_36 (Ba  (None, 29, 29, 32)        128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_89 (MaxPooli  (None, 14, 14, 32)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_111 (Conv2D)         (None, 12, 12, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_37 (Ba  (None, 12, 12, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_90 (MaxPooli  (None, 6, 6, 64)          0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_112 (Conv2D)         (None, 4, 4, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_38 (Ba  (None, 4, 4, 64)          256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_91 (MaxPooli  (None, 2, 2, 64)          0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_31 (Flatten)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 64)                16448     \n",
            "                                                                 \n",
            " batch_normalization_39 (Ba  (None, 64)                256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 83300 (325.39 KB)\n",
            "Trainable params: 82788 (323.39 KB)\n",
            "Non-trainable params: 512 (2.00 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "203/203 [==============================] - 16s 70ms/step - loss: 1.0815 - accuracy: 0.5719 - val_loss: 1.6488 - val_accuracy: 0.3958\n",
            "Epoch 2/100\n",
            "203/203 [==============================] - 14s 68ms/step - loss: 0.8335 - accuracy: 0.6680 - val_loss: 1.1247 - val_accuracy: 0.5327\n",
            "Epoch 3/100\n",
            "203/203 [==============================] - 14s 67ms/step - loss: 0.7146 - accuracy: 0.7229 - val_loss: 0.8222 - val_accuracy: 0.6671\n",
            "Epoch 4/100\n",
            "203/203 [==============================] - 14s 68ms/step - loss: 0.6105 - accuracy: 0.7586 - val_loss: 0.8108 - val_accuracy: 0.6720\n",
            "Epoch 5/100\n",
            "203/203 [==============================] - 14s 68ms/step - loss: 0.5313 - accuracy: 0.7986 - val_loss: 0.6689 - val_accuracy: 0.7503\n",
            "Epoch 6/100\n",
            "203/203 [==============================] - 14s 67ms/step - loss: 0.4507 - accuracy: 0.8361 - val_loss: 0.7525 - val_accuracy: 0.7275\n",
            "Epoch 7/100\n",
            "203/203 [==============================] - 14s 67ms/step - loss: 0.4086 - accuracy: 0.8467 - val_loss: 0.8139 - val_accuracy: 0.7213\n",
            "Epoch 8/100\n",
            "203/203 [==============================] - 14s 67ms/step - loss: 0.3427 - accuracy: 0.8735 - val_loss: 0.7075 - val_accuracy: 0.7645\n",
            "Epoch 9/100\n",
            "203/203 [==============================] - 13s 66ms/step - loss: 0.2718 - accuracy: 0.9035 - val_loss: 0.7689 - val_accuracy: 0.7226\n",
            "Epoch 10/100\n",
            "203/203 [==============================] - 14s 67ms/step - loss: 0.2510 - accuracy: 0.9087 - val_loss: 0.8087 - val_accuracy: 0.7256\n",
            "Epoch 11/100\n",
            "203/203 [==============================] - 14s 67ms/step - loss: 0.2133 - accuracy: 0.9223 - val_loss: 0.7070 - val_accuracy: 0.7744\n",
            "Epoch 12/100\n",
            "203/203 [==============================] - 14s 67ms/step - loss: 0.2083 - accuracy: 0.9267 - val_loss: 0.6268 - val_accuracy: 0.8052\n",
            "Epoch 13/100\n",
            "203/203 [==============================] - 13s 66ms/step - loss: 0.1725 - accuracy: 0.9411 - val_loss: 0.9529 - val_accuracy: 0.7460\n",
            "Epoch 14/100\n",
            "203/203 [==============================] - 14s 67ms/step - loss: 0.1740 - accuracy: 0.9383 - val_loss: 0.8432 - val_accuracy: 0.7583\n",
            "Epoch 15/100\n",
            "203/203 [==============================] - 14s 68ms/step - loss: 0.1475 - accuracy: 0.9502 - val_loss: 1.0352 - val_accuracy: 0.7503\n",
            "Epoch 16/100\n",
            "203/203 [==============================] - 14s 67ms/step - loss: 0.1345 - accuracy: 0.9513 - val_loss: 0.7707 - val_accuracy: 0.7935\n",
            "Epoch 17/100\n",
            "203/203 [==============================] - 13s 66ms/step - loss: 0.1244 - accuracy: 0.9556 - val_loss: 0.9523 - val_accuracy: 0.7411\n",
            "Epoch 18/100\n",
            "203/203 [==============================] - 14s 68ms/step - loss: 0.1320 - accuracy: 0.9551 - val_loss: 1.6951 - val_accuracy: 0.6258\n",
            "Epoch 19/100\n",
            "203/203 [==============================] - 14s 68ms/step - loss: 0.1088 - accuracy: 0.9636 - val_loss: 0.9834 - val_accuracy: 0.7503\n",
            "Epoch 20/100\n",
            "203/203 [==============================] - 16s 77ms/step - loss: 0.1003 - accuracy: 0.9665 - val_loss: 1.1261 - val_accuracy: 0.7367\n",
            "Epoch 21/100\n",
            "203/203 [==============================] - 15s 72ms/step - loss: 0.0952 - accuracy: 0.9667 - val_loss: 0.8605 - val_accuracy: 0.7774\n",
            "Epoch 22/100\n",
            "203/203 [==============================] - 14s 67ms/step - loss: 0.0833 - accuracy: 0.9696 - val_loss: 0.9244 - val_accuracy: 0.7805\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e94f18cd510>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple CNN Architecture 1.5\n",
        "\n",
        "# Data Augmentation\n",
        "\n",
        "We will now use data augmentation to increase the amount of data that we have, to try and mitigate the high variance issue that we are facing.\n",
        "\n",
        "```\n",
        "No DA: loss: 0.0855 - accuracy: 0.9718 - val_loss: 0.8041 - val_accuracy: 0.8033\n",
        "DA: loss: 0.5262 - accuracy: 0.8054 - val_loss: 0.5846 - val_accuracy: 0.7744\n",
        "```\n",
        "\n",
        "Data augmentation significantly worsened our train loss and accuracy but our validation loss became better and the difference between both accuracies have a gap of only 0.3!!! So now we have fixed our variance issue it is time to improve the complexity once again."
      ],
      "metadata": {
        "id": "VcW-CBEHijXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Simple CNN Architecture 1.5\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.activations import relu, linear\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#Data Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "datagen.fit(X_train_reshaped)\n",
        "\n",
        "\n",
        "#Early Stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss',\n",
        "                               patience=10,\n",
        "                               restore_best_weights=True)\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "#Convolutional Layer 1\n",
        "model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(rd,rd,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "\n",
        "#Convolutional Layer 2\n",
        "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "\n",
        "#Convolutional Layer 3\n",
        "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "\n",
        "#Convolutional Layer 4\n",
        "model.add(layers.Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "\n",
        "#Layer 5 Flatten\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "#Layer 6 Fully connected\n",
        "model.add(layers.Dense(64,activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.425))\n",
        "\n",
        "# Layer 7 Prediction\n",
        "model.add(layers.Dense(4,activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.fit(datagen.flow(x=X_train_reshaped,y=hi,batch_size=32),\n",
        "          epochs=100,\n",
        "          validation_data=(X_test_reshaped,ho),\n",
        "          callbacks=[early_stopping]\n",
        "          )"
      ],
      "metadata": {
        "id": "shjxWoXxCAuJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3091daf-b901-45ca-fbc6-fd38fdaa1a3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 62, 62, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 31, 31, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 29, 29, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 29, 29, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 14, 14, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 12, 12, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 12, 12, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 6, 6, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 4, 4, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_8 (Bat  (None, 4, 4, 128)         512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 2, 2, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " batch_normalization_9 (Bat  (None, 64)                256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 164676 (643.27 KB)\n",
            "Trainable params: 163972 (640.52 KB)\n",
            "Non-trainable params: 704 (2.75 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "203/203 [==============================] - 21s 93ms/step - loss: 1.4461 - accuracy: 0.4271 - val_loss: 1.8994 - val_accuracy: 0.2633\n",
            "Epoch 2/100\n",
            "203/203 [==============================] - 19s 91ms/step - loss: 1.1626 - accuracy: 0.5204 - val_loss: 1.2094 - val_accuracy: 0.4605\n",
            "Epoch 3/100\n",
            "203/203 [==============================] - 17s 83ms/step - loss: 1.1004 - accuracy: 0.5484 - val_loss: 1.1677 - val_accuracy: 0.5086\n",
            "Epoch 4/100\n",
            "203/203 [==============================] - 17s 82ms/step - loss: 1.0313 - accuracy: 0.5702 - val_loss: 1.1887 - val_accuracy: 0.5123\n",
            "Epoch 5/100\n",
            "203/203 [==============================] - 17s 82ms/step - loss: 0.9864 - accuracy: 0.5984 - val_loss: 0.9603 - val_accuracy: 0.5888\n",
            "Epoch 6/100\n",
            "203/203 [==============================] - 17s 84ms/step - loss: 0.9402 - accuracy: 0.6189 - val_loss: 0.9848 - val_accuracy: 0.5820\n",
            "Epoch 7/100\n",
            "203/203 [==============================] - 17s 85ms/step - loss: 0.9418 - accuracy: 0.6178 - val_loss: 0.9818 - val_accuracy: 0.6221\n",
            "Epoch 8/100\n",
            "203/203 [==============================] - 17s 84ms/step - loss: 0.8982 - accuracy: 0.6431 - val_loss: 1.2708 - val_accuracy: 0.4883\n",
            "Epoch 9/100\n",
            "203/203 [==============================] - 17s 82ms/step - loss: 0.8599 - accuracy: 0.6649 - val_loss: 0.8648 - val_accuracy: 0.6473\n",
            "Epoch 10/100\n",
            "203/203 [==============================] - 17s 83ms/step - loss: 0.8326 - accuracy: 0.6774 - val_loss: 1.1036 - val_accuracy: 0.5962\n",
            "Epoch 11/100\n",
            "203/203 [==============================] - 17s 83ms/step - loss: 0.8287 - accuracy: 0.6781 - val_loss: 0.8406 - val_accuracy: 0.6523\n",
            "Epoch 12/100\n",
            "203/203 [==============================] - 16s 81ms/step - loss: 0.8147 - accuracy: 0.6845 - val_loss: 1.3746 - val_accuracy: 0.5407\n",
            "Epoch 13/100\n",
            "203/203 [==============================] - 17s 81ms/step - loss: 0.7956 - accuracy: 0.6934 - val_loss: 0.7651 - val_accuracy: 0.6948\n",
            "Epoch 14/100\n",
            "203/203 [==============================] - 17s 82ms/step - loss: 0.7777 - accuracy: 0.6982 - val_loss: 0.9841 - val_accuracy: 0.5863\n",
            "Epoch 15/100\n",
            "203/203 [==============================] - 17s 83ms/step - loss: 0.7474 - accuracy: 0.7113 - val_loss: 0.8071 - val_accuracy: 0.6813\n",
            "Epoch 16/100\n",
            "203/203 [==============================] - 17s 83ms/step - loss: 0.7380 - accuracy: 0.7182 - val_loss: 0.8327 - val_accuracy: 0.6837\n",
            "Epoch 17/100\n",
            "203/203 [==============================] - 17s 84ms/step - loss: 0.7148 - accuracy: 0.7215 - val_loss: 0.8007 - val_accuracy: 0.6831\n",
            "Epoch 18/100\n",
            "203/203 [==============================] - 17s 82ms/step - loss: 0.7317 - accuracy: 0.7216 - val_loss: 0.8133 - val_accuracy: 0.6985\n",
            "Epoch 19/100\n",
            "203/203 [==============================] - 17s 83ms/step - loss: 0.7061 - accuracy: 0.7316 - val_loss: 1.2197 - val_accuracy: 0.5974\n",
            "Epoch 20/100\n",
            "203/203 [==============================] - 17s 83ms/step - loss: 0.7067 - accuracy: 0.7315 - val_loss: 0.6795 - val_accuracy: 0.7361\n",
            "Epoch 21/100\n",
            "203/203 [==============================] - 17s 82ms/step - loss: 0.6775 - accuracy: 0.7486 - val_loss: 1.0173 - val_accuracy: 0.6141\n",
            "Epoch 22/100\n",
            "203/203 [==============================] - 17s 85ms/step - loss: 0.6872 - accuracy: 0.7395 - val_loss: 1.2154 - val_accuracy: 0.5771\n",
            "Epoch 23/100\n",
            "203/203 [==============================] - 17s 84ms/step - loss: 0.6684 - accuracy: 0.7452 - val_loss: 0.7792 - val_accuracy: 0.7041\n",
            "Epoch 24/100\n",
            "203/203 [==============================] - 17s 83ms/step - loss: 0.6578 - accuracy: 0.7543 - val_loss: 1.1415 - val_accuracy: 0.6067\n",
            "Epoch 25/100\n",
            "203/203 [==============================] - 17s 84ms/step - loss: 0.6390 - accuracy: 0.7622 - val_loss: 1.0024 - val_accuracy: 0.5882\n",
            "Epoch 26/100\n",
            "203/203 [==============================] - 17s 83ms/step - loss: 0.6257 - accuracy: 0.7642 - val_loss: 1.1414 - val_accuracy: 0.6011\n",
            "Epoch 27/100\n",
            "203/203 [==============================] - 17s 83ms/step - loss: 0.6042 - accuracy: 0.7677 - val_loss: 0.6531 - val_accuracy: 0.7540\n",
            "Epoch 28/100\n",
            "203/203 [==============================] - 17s 82ms/step - loss: 0.6048 - accuracy: 0.7734 - val_loss: 0.6975 - val_accuracy: 0.7386\n",
            "Epoch 29/100\n",
            "203/203 [==============================] - 17s 82ms/step - loss: 0.6047 - accuracy: 0.7705 - val_loss: 0.7555 - val_accuracy: 0.7287\n",
            "Epoch 30/100\n",
            "203/203 [==============================] - 17s 82ms/step - loss: 0.5838 - accuracy: 0.7801 - val_loss: 0.5376 - val_accuracy: 0.8052\n",
            "Epoch 31/100\n",
            "203/203 [==============================] - 17s 82ms/step - loss: 0.5891 - accuracy: 0.7810 - val_loss: 0.9389 - val_accuracy: 0.6529\n",
            "Epoch 32/100\n",
            "203/203 [==============================] - 17s 83ms/step - loss: 0.5688 - accuracy: 0.7882 - val_loss: 0.7092 - val_accuracy: 0.7367\n",
            "Epoch 33/100\n",
            "203/203 [==============================] - 16s 81ms/step - loss: 0.5878 - accuracy: 0.7832 - val_loss: 0.6988 - val_accuracy: 0.7226\n",
            "Epoch 34/100\n",
            "203/203 [==============================] - 16s 81ms/step - loss: 0.5448 - accuracy: 0.8006 - val_loss: 0.5668 - val_accuracy: 0.7879\n",
            "Epoch 35/100\n",
            "203/203 [==============================] - 17s 81ms/step - loss: 0.5585 - accuracy: 0.7916 - val_loss: 0.6314 - val_accuracy: 0.7583\n",
            "Epoch 36/100\n",
            "203/203 [==============================] - 16s 80ms/step - loss: 0.5556 - accuracy: 0.7938 - val_loss: 0.7789 - val_accuracy: 0.7441\n",
            "Epoch 37/100\n",
            "203/203 [==============================] - 16s 81ms/step - loss: 0.5424 - accuracy: 0.8055 - val_loss: 0.7320 - val_accuracy: 0.7448\n",
            "Epoch 38/100\n",
            "203/203 [==============================] - 16s 80ms/step - loss: 0.5269 - accuracy: 0.8043 - val_loss: 1.1530 - val_accuracy: 0.6295\n",
            "Epoch 39/100\n",
            "203/203 [==============================] - 16s 81ms/step - loss: 0.5490 - accuracy: 0.7955 - val_loss: 0.6186 - val_accuracy: 0.7818\n",
            "Epoch 40/100\n",
            "203/203 [==============================] - 17s 82ms/step - loss: 0.5262 - accuracy: 0.8054 - val_loss: 0.5846 - val_accuracy: 0.7744\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fb97035e920>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Keras Tuning"
      ],
      "metadata": {
        "id": "cQ2yeG0p0mqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.activations import relu, linear\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from kerastuner.engine.hyperparameters import HyperParameters\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "class MyImageClassifierTuner:\n",
        "  def __init__(self,X_train,y_train,X_test,y_test):\n",
        "    self.X_train = X_train_reshaped\n",
        "    self.y_train = hi\n",
        "    self.X_test = X_test_reshaped\n",
        "    self.y_test = ho\n",
        "    self.tuner = None\n",
        "\n",
        "  def build_model(self,hp):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    ## Hyperparameter setting for Filter and Kernel\n",
        "    num_filters = hp.Int('num_filters',min_value=32,max_value=128,step=32)\n",
        "    kernel_size = hp.Int('kernel_size',min_value=3,max_value=5)\n",
        "\n",
        "    #Convolutional Layer 1\n",
        "    model.add(layers.Conv2D(num_filters,(kernel_size,kernel_size),activation='relu',input_shape=(rd,rd,3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D((2,2)))\n",
        "\n",
        "    #Convolutional Layer 2,3,4\n",
        "    for _ in range(3):\n",
        "      model.add(layers.Conv2D(num_filters,(kernel_size,kernel_size),activation='relu',padding='same'))\n",
        "      model.add(BatchNormalization())\n",
        "      model.add(layers.MaxPooling2D((2,2)))\n",
        "\n",
        "    #Flatten Layer 5\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    ## Hyperparameter setting for Dense Neurons and Layers\n",
        "    dense_neurons = hp.Int('dense_neurons',min_value=32,max_value=160,step=32)\n",
        "    num_hidden_layers = hp.Int('num_hidden_layers',min_value=1,max_value=3)\n",
        "\n",
        "    #Fully Connected Dense Layers (6-8)\n",
        "    for _ in range(num_hidden_layers):\n",
        "      ## Hyperparameter setting for l1 l2 regularizers\n",
        "      model.add(Dense(dense_neurons,activation='relu',\n",
        "                      kernel_regularizer=regularizers.l1_l2(\n",
        "                          l1=hp.Float('l1_regularization',min_value=1e-6,max_value=1e-3,sampling='log'),\n",
        "                          l2=hp.Float('l2_regularization',min_value=1e-6,max_value=1e-3,sampling='log')\n",
        "                      )))\n",
        "      model.add(BatchNormalization())\n",
        "      model.add(layers.Dropout(0.425))\n",
        "\n",
        "    # Prediction Layer\n",
        "    model.add(layers.Dense(4,activation='softmax'))\n",
        "\n",
        "    ## Hyperparameter setting for learning rate\n",
        "    model.compile(optimizer=Adam(learning_rate=hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2, sampling=\"log\")),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "  ## Max_trials\n",
        "  def run_tuner(self):\n",
        "    self.tuner = RandomSearch(\n",
        "        self.build_model,\n",
        "        objective='val_accuracy',\n",
        "        max_trials=20, #Number of diff hyperparameter combinations to try\n",
        "        directory='my_tuner_directory', #Directory to store tuner logs and checkpoints\n",
        "        project_name='my_image_classifier', #Name of tuning project\n",
        "        )\n",
        "\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    datagen.fit(X_train_reshaped)\n",
        "    early_stopping = EarlyStopping(monitor='val_loss',patience=10,restore_best_weights=True)\n",
        "\n",
        "\n",
        "    self.tuner.search(datagen.flow(x=self.X_train,y=self.y_train,batch_size=32),\n",
        "                 epochs=100,\n",
        "                 validation_data=(self.X_test,self.y_test),\n",
        "                 callbacks=[early_stopping])\n",
        "\n",
        "    best_hps = self.tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "    best_model = self.tuner.hypermodel.build(best_hps)\n",
        "\n",
        "    best_model.fit(datagen.flow(x=self.X_train,y=self.y_train,batch_size=32),\n",
        "                 epochs=100,\n",
        "                 validation_data=(self.X_test,self.y_test),\n",
        "                 callbacks=[early_stopping])\n",
        "\n",
        "  ##Get best hyperparameters\n",
        "  def get_best_hyperparameters(self):\n",
        "    best_hps = self.tuner.get_best_hyperparameters()[0]\n",
        "\n",
        "    best_num_filters = best_hps.get('num_filters')\n",
        "    best_kernel_size = best_hps.get('kernel_size')\n",
        "    best_dense_neurons = best_hps.get('dense_neurons')\n",
        "    best_num_hidden_layers = best_hps.get('num_hidden_layers')\n",
        "    best_l1_regularization = best_hps.get('l1_regularization')\n",
        "    best_l2_regularization = best_hps.get('l2_regularization')\n",
        "    best_learning_rate = best_hps.get('learning_rate')\n",
        "\n",
        "    return (best_num_filters, best_kernel_size, best_dense_neurons, best_num_hidden_layers, best_l1_regularization, best_l2_regularization, best_learning_rate)\n",
        "\n",
        "\n",
        "\n",
        "tuner = MyImageClassifierTuner(X_train_reshaped,hi,X_test_reshaped,ho)\n",
        "tuner.run_tuner()\n",
        "\n",
        "## Obtain best hyperparameters\n",
        "best_hyperparameters = tuner.get_best_hyperparameters()\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(f\"Number of Filters: {best_hyperparameters[0]}\")\n",
        "print(f\"Kernel Size: {best_hyperparameters[1]}\")\n",
        "print(f\"Dense Neurons: {best_hyperparameters[2]}\")\n",
        "print(f\"Number of Hidden Layers: {best_hyperparameters[3]}\")\n",
        "print(f\"L1 Regularization: {best_hyperparameters[4]}\")\n",
        "print(f\"L2 Regularization: {best_hyperparameters[5]}\")\n",
        "print(f\"Learning Rate: {best_hyperparameters[6]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "h9myZNts0p0B",
        "outputId": "053589c8-d388-4fa6-89be-0da63dab6c08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 13 Complete [00h 58m 38s]\n",
            "val_accuracy: 0.76325523853302\n",
            "\n",
            "Best val_accuracy So Far: 0.8162761926651001\n",
            "Total elapsed time: 05h 05m 45s\n",
            "\n",
            "Search: Running Trial #14\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "96                |64                |num_filters\n",
            "3                 |3                 |kernel_size\n",
            "128               |96                |dense_neurons\n",
            "2                 |1                 |num_hidden_layers\n",
            "1.4261e-05        |0.0001142         |l1_regularization\n",
            "0.00067424        |1.1324e-05        |l2_regularization\n",
            "0.0001552         |0.00025845        |learning_rate\n",
            "\n",
            "Epoch 1/100\n",
            "203/203 [==============================] - 53s 247ms/step - loss: 2.1079 - accuracy: 0.3544 - val_loss: 1.9035 - val_accuracy: 0.2676\n",
            "Epoch 2/100\n",
            "203/203 [==============================] - 49s 242ms/step - loss: 1.8239 - accuracy: 0.4240 - val_loss: 1.6327 - val_accuracy: 0.4069\n",
            "Epoch 3/100\n",
            "203/203 [==============================] - 50s 244ms/step - loss: 1.7281 - accuracy: 0.4411 - val_loss: 1.3880 - val_accuracy: 0.5382\n",
            "Epoch 4/100\n",
            "203/203 [==============================] - 50s 245ms/step - loss: 1.6591 - accuracy: 0.4732 - val_loss: 1.3013 - val_accuracy: 0.6042\n",
            "Epoch 5/100\n",
            "203/203 [==============================] - 49s 241ms/step - loss: 1.5865 - accuracy: 0.4917 - val_loss: 1.3316 - val_accuracy: 0.5962\n",
            "Epoch 6/100\n",
            "203/203 [==============================] - 50s 244ms/step - loss: 1.5551 - accuracy: 0.4968 - val_loss: 1.3464 - val_accuracy: 0.5684\n",
            "Epoch 7/100\n",
            "203/203 [==============================] - 50s 245ms/step - loss: 1.4846 - accuracy: 0.5342 - val_loss: 1.3258 - val_accuracy: 0.5931\n",
            "Epoch 8/100\n",
            "203/203 [==============================] - 50s 244ms/step - loss: 1.4428 - accuracy: 0.5379 - val_loss: 1.2388 - val_accuracy: 0.6282\n",
            "Epoch 9/100\n",
            "203/203 [==============================] - 49s 243ms/step - loss: 1.4295 - accuracy: 0.5452 - val_loss: 1.5261 - val_accuracy: 0.5271\n",
            "Epoch 10/100\n",
            "203/203 [==============================] - 49s 240ms/step - loss: 1.3907 - accuracy: 0.5622 - val_loss: 1.2786 - val_accuracy: 0.6085\n",
            "Epoch 11/100\n",
            "203/203 [==============================] - 50s 245ms/step - loss: 1.3687 - accuracy: 0.5733 - val_loss: 1.2353 - val_accuracy: 0.6196\n",
            "Epoch 12/100\n",
            "203/203 [==============================] - 50s 247ms/step - loss: 1.3408 - accuracy: 0.5905 - val_loss: 1.6200 - val_accuracy: 0.5228\n",
            "Epoch 13/100\n",
            "203/203 [==============================] - 50s 245ms/step - loss: 1.3213 - accuracy: 0.5902 - val_loss: 1.1318 - val_accuracy: 0.6868\n",
            "Epoch 14/100\n",
            "203/203 [==============================] - 49s 241ms/step - loss: 1.2881 - accuracy: 0.6047 - val_loss: 1.2705 - val_accuracy: 0.6054\n",
            "Epoch 15/100\n",
            "203/203 [==============================] - 49s 243ms/step - loss: 1.2630 - accuracy: 0.6075 - val_loss: 1.1627 - val_accuracy: 0.6603\n",
            "Epoch 16/100\n",
            "203/203 [==============================] - 49s 241ms/step - loss: 1.2307 - accuracy: 0.6303 - val_loss: 1.2128 - val_accuracy: 0.6313\n",
            "Epoch 17/100\n",
            "203/203 [==============================] - 50s 244ms/step - loss: 1.2073 - accuracy: 0.6396 - val_loss: 1.3833 - val_accuracy: 0.5956\n",
            "Epoch 18/100\n",
            "203/203 [==============================] - 49s 241ms/step - loss: 1.1925 - accuracy: 0.6411 - val_loss: 1.0604 - val_accuracy: 0.7115\n",
            "Epoch 19/100\n",
            "203/203 [==============================] - 49s 241ms/step - loss: 1.1806 - accuracy: 0.6479 - val_loss: 1.0192 - val_accuracy: 0.7238\n",
            "Epoch 20/100\n",
            "203/203 [==============================] - 49s 241ms/step - loss: 1.1581 - accuracy: 0.6505 - val_loss: 1.1126 - val_accuracy: 0.6739\n",
            "Epoch 21/100\n",
            "203/203 [==============================] - 49s 241ms/step - loss: 1.1482 - accuracy: 0.6595 - val_loss: 1.1544 - val_accuracy: 0.6621\n",
            "Epoch 22/100\n",
            "203/203 [==============================] - 50s 244ms/step - loss: 1.1329 - accuracy: 0.6720 - val_loss: 1.0513 - val_accuracy: 0.6899\n",
            "Epoch 23/100\n",
            "203/203 [==============================] - 50s 246ms/step - loss: 1.1099 - accuracy: 0.6758 - val_loss: 1.0085 - val_accuracy: 0.7281\n",
            "Epoch 24/100\n",
            "203/203 [==============================] - 50s 246ms/step - loss: 1.0997 - accuracy: 0.6874 - val_loss: 1.0654 - val_accuracy: 0.6991\n",
            "Epoch 25/100\n",
            "203/203 [==============================] - 50s 246ms/step - loss: 1.0834 - accuracy: 0.6897 - val_loss: 1.3817 - val_accuracy: 0.5906\n",
            "Epoch 26/100\n",
            "203/203 [==============================] - 50s 245ms/step - loss: 1.0464 - accuracy: 0.7011 - val_loss: 0.9248 - val_accuracy: 0.7620\n",
            "Epoch 27/100\n",
            "203/203 [==============================] - 49s 242ms/step - loss: 1.0558 - accuracy: 0.6966 - val_loss: 1.0441 - val_accuracy: 0.7090\n",
            "Epoch 28/100\n",
            "203/203 [==============================] - 49s 243ms/step - loss: 1.0315 - accuracy: 0.7060 - val_loss: 0.9612 - val_accuracy: 0.7343\n",
            "Epoch 29/100\n",
            "203/203 [==============================] - 49s 242ms/step - loss: 1.0133 - accuracy: 0.7096 - val_loss: 1.0678 - val_accuracy: 0.6874\n",
            "Epoch 30/100\n",
            "203/203 [==============================] - 49s 240ms/step - loss: 0.9954 - accuracy: 0.7150 - val_loss: 0.9482 - val_accuracy: 0.7411\n",
            "Epoch 31/100\n",
            "203/203 [==============================] - 49s 239ms/step - loss: 0.9944 - accuracy: 0.7212 - val_loss: 0.9041 - val_accuracy: 0.7707\n",
            "Epoch 32/100\n",
            "203/203 [==============================] - 50s 244ms/step - loss: 0.9697 - accuracy: 0.7287 - val_loss: 1.2342 - val_accuracy: 0.6356\n",
            "Epoch 33/100\n",
            "203/203 [==============================] - 50s 244ms/step - loss: 0.9695 - accuracy: 0.7253 - val_loss: 1.0887 - val_accuracy: 0.6868\n",
            "Epoch 34/100\n",
            "203/203 [==============================] - 50s 245ms/step - loss: 0.9557 - accuracy: 0.7353 - val_loss: 1.1547 - val_accuracy: 0.6726\n",
            "Epoch 35/100\n",
            "203/203 [==============================] - 50s 244ms/step - loss: 0.9300 - accuracy: 0.7423 - val_loss: 0.8619 - val_accuracy: 0.7731\n",
            "Epoch 36/100\n",
            "203/203 [==============================] - 49s 243ms/step - loss: 0.9278 - accuracy: 0.7414 - val_loss: 0.9526 - val_accuracy: 0.7367\n",
            "Epoch 37/100\n",
            "203/203 [==============================] - 49s 242ms/step - loss: 0.8973 - accuracy: 0.7540 - val_loss: 0.8511 - val_accuracy: 0.7682\n",
            "Epoch 38/100\n",
            "203/203 [==============================] - 49s 243ms/step - loss: 0.9071 - accuracy: 0.7448 - val_loss: 0.9075 - val_accuracy: 0.7596\n",
            "Epoch 39/100\n",
            "203/203 [==============================] - 50s 244ms/step - loss: 0.8792 - accuracy: 0.7572 - val_loss: 0.8101 - val_accuracy: 0.7861\n",
            "Epoch 40/100\n",
            "203/203 [==============================] - 50s 247ms/step - loss: 0.8751 - accuracy: 0.7554 - val_loss: 0.8939 - val_accuracy: 0.7503\n",
            "Epoch 41/100\n",
            "203/203 [==============================] - 50s 246ms/step - loss: 0.8454 - accuracy: 0.7704 - val_loss: 0.7535 - val_accuracy: 0.7959\n",
            "Epoch 42/100\n",
            "203/203 [==============================] - 50s 245ms/step - loss: 0.8329 - accuracy: 0.7812 - val_loss: 0.9521 - val_accuracy: 0.7466\n",
            "Epoch 43/100\n",
            "203/203 [==============================] - 49s 241ms/step - loss: 0.8156 - accuracy: 0.7785 - val_loss: 0.8485 - val_accuracy: 0.7509\n",
            "Epoch 44/100\n",
            "203/203 [==============================] - 49s 242ms/step - loss: 0.8027 - accuracy: 0.7804 - val_loss: 0.7886 - val_accuracy: 0.7935\n",
            "Epoch 45/100\n",
            "203/203 [==============================] - 49s 242ms/step - loss: 0.8153 - accuracy: 0.7756 - val_loss: 1.1054 - val_accuracy: 0.6893\n",
            "Epoch 46/100\n",
            "203/203 [==============================] - 49s 241ms/step - loss: 0.7916 - accuracy: 0.7830 - val_loss: 0.8921 - val_accuracy: 0.7546\n",
            "Epoch 47/100\n",
            "203/203 [==============================] - 49s 240ms/step - loss: 0.7663 - accuracy: 0.7918 - val_loss: 0.7908 - val_accuracy: 0.7848\n",
            "Epoch 48/100\n",
            "203/203 [==============================] - 49s 242ms/step - loss: 0.7931 - accuracy: 0.7852 - val_loss: 0.8540 - val_accuracy: 0.7367\n",
            "Epoch 49/100\n",
            "203/203 [==============================] - 49s 241ms/step - loss: 0.7576 - accuracy: 0.7938 - val_loss: 0.7778 - val_accuracy: 0.7904\n",
            "Epoch 50/100\n",
            "203/203 [==============================] - 49s 240ms/step - loss: 0.7470 - accuracy: 0.7970 - val_loss: 0.8823 - val_accuracy: 0.7546\n",
            "Epoch 51/100\n",
            "203/203 [==============================] - 49s 242ms/step - loss: 0.7526 - accuracy: 0.7961 - val_loss: 0.7323 - val_accuracy: 0.8033\n",
            "Epoch 52/100\n",
            "203/203 [==============================] - 49s 242ms/step - loss: 0.7438 - accuracy: 0.7904 - val_loss: 0.6998 - val_accuracy: 0.8169\n",
            "Epoch 53/100\n",
            "203/203 [==============================] - 49s 239ms/step - loss: 0.7398 - accuracy: 0.7981 - val_loss: 0.7333 - val_accuracy: 0.7959\n",
            "Epoch 54/100\n",
            "203/203 [==============================] - 49s 242ms/step - loss: 0.7339 - accuracy: 0.7936 - val_loss: 0.8851 - val_accuracy: 0.7491\n",
            "Epoch 55/100\n",
            "203/203 [==============================] - 49s 240ms/step - loss: 0.7129 - accuracy: 0.8092 - val_loss: 0.8165 - val_accuracy: 0.7750\n",
            "Epoch 56/100\n",
            "203/203 [==============================] - 49s 242ms/step - loss: 0.6922 - accuracy: 0.8111 - val_loss: 0.7697 - val_accuracy: 0.7959\n",
            "Epoch 57/100\n",
            "203/203 [==============================] - 49s 243ms/step - loss: 0.7097 - accuracy: 0.8069 - val_loss: 0.7310 - val_accuracy: 0.8169\n",
            "Epoch 58/100\n",
            "203/203 [==============================] - 50s 244ms/step - loss: 0.6923 - accuracy: 0.8092 - val_loss: 0.8164 - val_accuracy: 0.7824\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-019708fac4a2>\u001b[0m in \u001b[0;36m<cell line: 125>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0mtuner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyImageClassifierTuner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_reshaped\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test_reshaped\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_tuner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;31m## Obtain best hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-019708fac4a2>\u001b[0m in \u001b[0;36mrun_tuner\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     self.tuner.search(datagen.flow(x=self.X_train,y=self.y_train,batch_size=32),\n\u001b[0m\u001b[1;32m     95\u001b[0m                  \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                  \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36m_try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36m_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         if self.oracle.get_trial(trial.trial_id).metrics.exists(\n\u001b[1;32m    237\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         tuner_utils.validate_trial_results(\n\u001b[1;32m    216\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HyperModel.fit()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \"\"\"\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1728\u001b[0m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1730\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1731\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1732\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2598\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2600\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2601\u001b[0m         \"\"\"Resets the state of all the metrics in the model.\n\u001b[1;32m   2602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "qGEK3di71USW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}